{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Load torch device",
   "id": "7290dc158ded658b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from Datasets.ncaltech101 import NCaltech\n",
    "import torch\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from torch.optim import Adam\n",
    "from Datasets.batching import BatchManager\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ],
   "id": "5f162807b329b0b3"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Model Initialization",
   "id": "a6766c913cfc3888"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from Models.CleanAEGNN.GraphRes import GraphRes as AEGNN\n",
    "from torch_geometric.data import Data as PyGData\n",
    "\n",
    "image_size: tuple[int, int] = NCaltech.get_info().image_size\n",
    "input_shape: tuple[int, int, int] = (*image_size, 3)\n",
    "\n",
    "model = AEGNN(\n",
    "    input_shape = input_shape,\n",
    "    kernel_size = 8,\n",
    "    n = [1, 16, 32, 32, 32, 128, 128, 128],\n",
    "    pooling_outputs = 128,\n",
    "    num_outputs = len(NCaltech.get_info().classes),\n",
    ").to(device)\n",
    "\n",
    "def transform_graph(graph: PyGData) -> PyGData:\n",
    "    graph = model.data_transform(\n",
    "        graph, n_samples = 25000, sampling = True,\n",
    "        beta =  0.5e-5, radius = 5.0,\n",
    "        max_neighbors = 32\n",
    "    ).to(device)\n",
    "    return graph"
   ],
   "id": "5ae311c58458abcb"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Dataset Initialization and processing (from the parsed dataset from the aegnn issues thread)",
   "id": "5758ebe7f4da8dfa"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "#Instantiating the ncaltech dataset\n",
    "ncaltech = NCaltech(\n",
    "    root=r\"D:\\Uniwersytet\\GNNBenchmarking\\Datasets\\NCaltech\",\n",
    "    transform=transform_graph\n",
    ")\n",
    "\n",
    "# Processing the training part of the dataset\n",
    "ncaltech.process(modes = [\"training\"])"
   ],
   "id": "8354afb70e3984dc"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Display example events data point",
   "id": "b7b037f305867616"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "training_set = BatchManager(\n",
    "    dataset=ncaltech,\n",
    "    batch_size=4,\n",
    "    mode=\"training\"\n",
    ")"
   ],
   "id": "8f82038a73881654"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "optimizer = Adam(model.parameters(), lr=5e-5)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=25, cooldown = 20)\n",
    "\n",
    "loss_fn = CrossEntropyLoss()\n",
    "\n",
    "classes = ncaltech.get_info().classes\n",
    "\n",
    "cls_to_idx = dict(zip(classes, range(len(classes))))"
   ],
   "id": "67eb49ce626ae89a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "model.train()\n",
    "for i in range(400):\n",
    "    examples = next(training_set)\n",
    "    reference = torch.tensor([cls_to_idx[cls] for cls in examples.label], dtype=torch.long).to(device)\n",
    "    out = model(examples)\n",
    "    loss = loss_fn(out, reference)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    scheduler.step(loss)\n",
    "    print(f\"Epoch {i}, learning rate: {scheduler.get_last_lr()[0]}\")\n",
    "    print(f\"Loss: {loss.item()}\")\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    del reference\n",
    "    del examples\n",
    "\n",
    "torch.save(model.state_dict(), \"../../TrainedModels/aegnn_trained_epoch_400.pth\")\n",
    "\n",
    "model.eval()\n",
    "predictions_made = 0\n",
    "correct = 0\n",
    "with torch.no_grad():\n",
    "    for i in range(50):\n",
    "        examples = next(training_set)\n",
    "        reference = torch.tensor([cls_to_idx[cls] for cls in examples.label], dtype=torch.long).to(device)\n",
    "        out = model(examples)\n",
    "        prediction = out.argmax(dim = -1)\n",
    "        is_correct = prediction - reference\n",
    "        is_correct = is_correct[is_correct == 0]\n",
    "        correct += is_correct.shape[0]\n",
    "        predictions_made += prediction.shape[0]\n",
    "\n",
    "        print(f\"Accuracy: {correct / predictions_made}\")\n",
    "\n",
    "print(f\"Accuracy: {correct / predictions_made}\")"
   ],
   "id": "cc0f54e26ca06df1"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GNNproj",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
