{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7f84d5b8",
   "metadata": {},
   "source": [
    "\n",
    "# NCars Event-GNN Training (SAGE/GCN) â€” with AEGNN Async Eval\n",
    "\n",
    "- Loads NCars sequences from `{train, validation, test}`\n",
    "- Builds k-NN graphs in (x, y, t)\n",
    "- Trains a **SAGE** or **GCN** encoder + classifier head\n",
    "- Optionally wraps the **encoder only** with `AEGNNAsyncWrapper` for asynchronous evaluation\n",
    "- Lets us limit the number of sequences per split for quick tests\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "4b54b865",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-28T14:30:45.144335Z",
     "start_time": "2025-10-28T14:30:45.120452Z"
    }
   },
   "source": [
    "\n",
    "# data folder containing 'training/', 'validation/', 'test/'\n",
    "DATA = r\"C:\\Users\\hanne\\Documents\\Hannes\\Uni\\Maastricht\\Project\\GNNBenchmark\\src\\Models\\AEGNN\\data\\ncars\"\n",
    "\n",
    "# If your events file has a specific name (else the dataset will auto-pick the first *.txt != is_car.txt)\n",
    "EVENTS_NAME = None  # should be \"events.txt\"\n",
    "\n",
    "# Sensor width,height (string \"W,H\") or None to normalize per-sequence\n",
    "SENSOR_WH = \"304,240\"  # or None\n",
    "\n",
    "# Graph building\n",
    "K = 8\n",
    "MAX_EVENTS = 1000  # reduce (e.g., 1000) for faster first run\n",
    "\n",
    "# Model\n",
    "MODEL = \"sage\"     # \"sage\" or \"gcn\"\n",
    "HIDDEN = 64\n",
    "DROPOUT = 0.2\n",
    "\n",
    "# Training\n",
    "EPOCHS = 30\n",
    "BATCH_SIZE = 32\n",
    "LR = 1e-3\n",
    "WD = 0.0\n",
    "\n",
    "# Use only first N (20) sequences per split (0 = all), for quick testing\n",
    "LIMIT_PER_SPLIT = 20\n",
    "\n",
    "# Async encoder wrapping at evaluation\n",
    "ASYNC_EVAL = True\n"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "id": "228e5683",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-28T14:30:56.285824Z",
     "start_time": "2025-10-28T14:30:45.173676Z"
    }
   },
   "source": [
    "\n",
    "import sys, os, pathlib\n",
    "project_root_candidates = [\n",
    "    pathlib.Path.cwd(),                                  # current directory\n",
    "    pathlib.Path.cwd().parents[0],                       # 1 level up\n",
    "    pathlib.Path.cwd().parents[1],                       # 2 levels up\n",
    "]\n",
    "for pr in project_root_candidates:\n",
    "    if str(pr) not in sys.path:\n",
    "        sys.path.append(str(pr))\n",
    "\n",
    "from pathlib import Path\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import Adam\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.loader import DataLoader\n",
    "\n",
    "# moduls needed\n",
    "from ProcessNCars import NCarsEventsGraphDataset\n",
    "from GCNEncoder import GCNEncoder\n",
    "from SAGEEncoder import SAGEEncoder\n",
    "from FullModel_GCN_SAGE import FullModel, ClassifierHead\n",
    "from train_ncars_from_events import train_one_epoch, evaluate, take_first\n"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#",
   "id": "f76c52149287f5fe"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Data Loading\n",
   "id": "cf7d83fc1bef5461"
  },
  {
   "cell_type": "code",
   "id": "098c1897",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-28T14:31:07.369123Z",
     "start_time": "2025-10-28T14:30:56.988911Z"
    }
   },
   "source": [
    "# dataset setup\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "sensor_wh = None\n",
    "if SENSOR_WH:\n",
    "    w, h = [int(s.strip()) for s in SENSOR_WH.split(\",\")]\n",
    "    sensor_wh = (w, h)\n",
    "\n",
    "root = Path(DATA)\n",
    "train_dir = root / \"training\"#change to your data path\n",
    "val_dir   = root / \"validation\"\n",
    "test_dir  = root / \"test\"\n",
    "for d in [train_dir, val_dir, test_dir]:\n",
    "    assert d.exists(), f\"Missing split directory: {d}\"\n",
    "\n",
    "precompute_gcn = (MODEL == \"gcn\")\n",
    "\n",
    "train_ds = NCarsEventsGraphDataset(str(train_dir), EVENTS_NAME, K, MAX_EVENTS,\n",
    "                                   sensor_wh, precompute_gcn, cache=True)\n",
    "val_ds   = NCarsEventsGraphDataset(str(val_dir),   EVENTS_NAME, K, MAX_EVENTS,\n",
    "                                   sensor_wh, precompute_gcn, cache=True)\n",
    "test_ds  = NCarsEventsGraphDataset(str(test_dir),  EVENTS_NAME, K, MAX_EVENTS,\n",
    "                                   sensor_wh, precompute_gcn, cache=True)\n",
    "\n",
    "# Limit for quick runs and testing\n",
    "if LIMIT_PER_SPLIT and LIMIT_PER_SPLIT > 0:\n",
    "    train_ds = take_first(train_ds, LIMIT_PER_SPLIT)\n",
    "    val_ds   = take_first(val_ds, LIMIT_PER_SPLIT)\n",
    "    # Uncomment to also limit test set:\n",
    "    test_ds  = take_first(test_ds, LIMIT_PER_SPLIT)\n",
    "\n",
    "print(\"Datasets ready.\",\n",
    "      \"\\n  train:\", len(train_ds),\n",
    "      \"\\n  val:  \", len(val_ds),\n",
    "      \"\\n  test: \", len(test_ds))\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datasets ready. \n",
      "  train: 20 \n",
      "  val:   20 \n",
      "  test:  50\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Model, Loaders, Optimizer\n",
   "id": "9d9c75a301cec04"
  },
  {
   "cell_type": "code",
   "id": "3525e3b5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-28T14:31:07.704383Z",
     "start_time": "2025-10-28T14:31:07.483296Z"
    }
   },
   "source": [
    "# model\n",
    "sample: Data = train_ds[0]\n",
    "in_ch = sample.x.size(-1)\n",
    "num_classes = int(max(sample.y.max().item(), 1) + 1)\n",
    "\n",
    "if MODEL == \"sage\":\n",
    "    encoder = SAGEEncoder(in_ch, hid=HIDDEN)\n",
    "else:\n",
    "    encoder = GCNEncoder(in_ch, hid=HIDDEN)\n",
    "\n",
    "head = ClassifierHead(hid=HIDDEN, num_classes=num_classes, dropout=DROPOUT, bias=True)\n",
    "model = FullModel(encoder, head).to(device)\n",
    "\n",
    "# loaders\n",
    "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader   = DataLoader(val_ds,   batch_size=BATCH_SIZE, shuffle=False)\n",
    "test_loader  = DataLoader(test_ds,  batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "# Optimizer & loss\n",
    "opt = Adam(model.parameters(), lr=LR, weight_decay=WD)\n",
    "crit = nn.CrossEntropyLoss()\n",
    "\n",
    "print(model)\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FullModel(\n",
      "  (encoder): SAGEEncoder(\n",
      "    (c1): SAGEConv(4, 64, aggr=mean)\n",
      "    (c2): SAGEConv(64, 64, aggr=mean)\n",
      "  )\n",
      "  (head): ClassifierHead(\n",
      "    (fc): Linear(in_features=64, out_features=2, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hanne\\Documents\\Hannes\\Uni\\Maastricht\\Project\\GNNBenchmark\\src\\Models\\AEGNN\\ProcessNCars.py:57: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(cache_fp, map_location=\"cpu\")\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Training Loop",
   "id": "e3462885d7bc6854"
  },
  {
   "cell_type": "code",
   "id": "56e995f3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-28T14:31:36.481735Z",
     "start_time": "2025-10-28T14:31:07.769520Z"
    }
   },
   "source": [
    "\n",
    "#training loop\n",
    "best_val, best_state = 0.0, None\n",
    "for epoch in range(1, EPOCHS + 1):\n",
    "    tr_loss, tr_acc = train_one_epoch(model, train_loader, device, opt, crit)\n",
    "    va_loss, va_acc = evaluate(model, val_loader, device, crit)\n",
    "    if va_acc > best_val:\n",
    "        best_val = va_acc\n",
    "        best_state = {k: v.detach().cpu() for k, v in model.state_dict().items()}\n",
    "    print(f\"Epoch {epoch:03d} | train {tr_loss:.4f}/{tr_acc:.3f} | val {va_loss:.4f}/{va_acc:.3f}\")\n",
    "\n",
    "if best_state:\n",
    "    model.load_state_dict(best_state)\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 001 | train 0.6998/0.500 | val 0.7109/0.450\n",
      "Epoch 002 | train 0.6981/0.450 | val 0.7058/0.450\n",
      "Epoch 003 | train 0.6862/0.450 | val 0.7015/0.450\n",
      "Epoch 004 | train 0.6973/0.550 | val 0.6987/0.350\n",
      "Epoch 005 | train 0.7038/0.350 | val 0.6966/0.450\n",
      "Epoch 006 | train 0.6887/0.550 | val 0.6953/0.500\n",
      "Epoch 007 | train 0.6951/0.450 | val 0.6947/0.550\n",
      "Epoch 008 | train 0.7122/0.400 | val 0.6944/0.550\n",
      "Epoch 009 | train 0.7096/0.350 | val 0.6950/0.550\n",
      "Epoch 010 | train 0.6886/0.550 | val 0.6958/0.550\n",
      "Epoch 011 | train 0.6864/0.500 | val 0.6968/0.550\n",
      "Epoch 012 | train 0.6804/0.650 | val 0.6980/0.500\n",
      "Epoch 013 | train 0.6700/0.700 | val 0.6995/0.450\n",
      "Epoch 014 | train 0.6977/0.300 | val 0.7012/0.400\n",
      "Epoch 015 | train 0.6883/0.650 | val 0.7029/0.300\n",
      "Epoch 016 | train 0.6833/0.650 | val 0.7044/0.200\n",
      "Epoch 017 | train 0.6809/0.600 | val 0.7060/0.350\n",
      "Epoch 018 | train 0.7110/0.450 | val 0.7072/0.450\n",
      "Epoch 019 | train 0.6840/0.600 | val 0.7077/0.450\n",
      "Epoch 020 | train 0.6895/0.550 | val 0.7085/0.400\n",
      "Epoch 021 | train 0.6917/0.600 | val 0.7090/0.400\n",
      "Epoch 022 | train 0.6960/0.450 | val 0.7091/0.400\n",
      "Epoch 023 | train 0.6959/0.450 | val 0.7089/0.400\n",
      "Epoch 024 | train 0.6637/0.650 | val 0.7087/0.400\n",
      "Epoch 025 | train 0.6967/0.500 | val 0.7085/0.350\n",
      "Epoch 026 | train 0.7019/0.550 | val 0.7082/0.250\n",
      "Epoch 027 | train 0.6957/0.600 | val 0.7079/0.250\n",
      "Epoch 028 | train 0.6987/0.450 | val 0.7072/0.300\n",
      "Epoch 029 | train 0.6978/0.600 | val 0.7066/0.350\n",
      "Epoch 030 | train 0.6826/0.700 | val 0.7063/0.350\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Asynchronous Evaluation",
   "id": "daf32dd2e0157dc"
  },
  {
   "cell_type": "code",
   "id": "9c7ba40e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-28T14:31:36.624473Z",
     "start_time": "2025-10-28T14:31:36.513224Z"
    }
   },
   "source": [
    "\n",
    "\n",
    "# async for evaluation, only part taken from AEGNN\n",
    "if ASYNC_EVAL:\n",
    "    try:\n",
    "        from AEGNNwrapper import AEGNNAsyncWrapper\n",
    "        enc_async = AEGNNAsyncWrapper(model.encoder)\n",
    "        print(\"[AEGNN] is_async=\", getattr(enc_async, \"is_async\", False),\n",
    "              \"| why_not=\", getattr(enc_async, \"why_not_async\", None))\n",
    "        model.encoder = enc_async.to(device)\n",
    "    except Exception as e:\n",
    "        print(\"[AEGNN] Wrapper import failed; continuing without async. Reason:\", repr(e))\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[AEGNN] is_async= True | why_not= None\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-28T14:31:36.893560Z",
     "start_time": "2025-10-28T14:31:36.753365Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from tqdm import tqdm  # pip install tqdm (optional); else replace with a simple loop\n",
    "bad = []\n",
    "for i in range(len(test_ds)):\n",
    "    try:\n",
    "        _ = test_ds[i]\n",
    "    except Exception as e:\n",
    "        bad.append((i, str(test_ds.seq_dirs[i]), repr(e)))\n",
    "        print(\"BAD:\", i, test_ds.seq_dirs[i], e)\n",
    "\n",
    "print(\"bad count:\", len(bad))\n",
    "if bad:\n",
    "    print(\"examples:\", bad[:5])\n"
   ],
   "id": "9cbbe2347c47d1c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bad count: 0\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Testing\n",
   "id": "dbc1c976fa1c7708"
  },
  {
   "cell_type": "code",
   "id": "d2526355",
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2025-10-28T14:31:36.971801Z"
    }
   },
   "source": [
    "# test\n",
    "te_loss, te_acc = evaluate(model, test_loader, device, crit)\n",
    "print(f\"Test  | loss {te_loss:.4f} acc {te_acc:.3f}\")"
   ],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
