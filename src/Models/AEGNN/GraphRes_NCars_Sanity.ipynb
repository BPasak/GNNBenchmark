{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c143bbc6",
   "metadata": {},
   "source": [
    "\n",
    "# NCars + GraphRes (AEGNN-style) — Load & Forward Sanity Check\n",
    "\n",
    "This notebook verifies:\n",
    "- Loading **AEGNN-style** NCars graphs from `ProcessNCars1.NCarsEventsGraphDataset1`\n",
    "- Creating PyG DataLoaders\n",
    "- Running a **GraphRes** forward pass (uses `SplineConv` and expects `edge_attr=Cartesian`)\n",
    "\n",
    "> If `GraphRes` or `aegnn` package isn't importable here, a **minimal fallback** model will be defined so you can still test loading and a forward pass.\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "184aa0ab",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-08T12:58:35.798582Z",
     "start_time": "2025-11-08T12:58:31.367729Z"
    }
   },
   "source": [
    "\n",
    "# --- Configuration ---\n",
    "ROOT = r\"C:\\Users\\hanne\\Documents\\Hannes\\Uni\\Maastricht\\Project\\GNNBenchmark\\src\\Models\\AEGNN\\data\\ncars\"\n",
    "RADIUS = 3.0\n",
    "D_MAX  = 32\n",
    "N_SAMPLES = 10000\n",
    "SAMPLING  = True\n",
    "LIMIT_PER_SPLIT = 20\n",
    "\n",
    "import torch\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "DEVICE\n"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "id": "95db4e41",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-08T12:58:40.039806Z",
     "start_time": "2025-11-08T12:58:35.851179Z"
    }
   },
   "source": [
    "\n",
    "# Ensure we can import your uploaded ProcessNCars1.py from /mnt/data\n",
    "import sys\n",
    "from pathlib import Path\n",
    "if str(Path('/mnt/data')) not in sys.path:\n",
    "    sys.path.append(str(Path('/mnt/data')))\n",
    "\n",
    "from torch_geometric.loader import DataLoader\n",
    "\n",
    "try:\n",
    "    from ProcessNCars1 import NCarsEventsGraphDataset1\n",
    "    print(\"✅ Imported NCarsEventsGraphDataset1 from ProcessNCars1.py\")\n",
    "except Exception as e:\n",
    "    print(\"❌ Could not import NCarsEventsGraphDataset1:\", repr(e))\n",
    "    raise\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Imported NCarsEventsGraphDataset1 from ProcessNCars1.py\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "id": "3de98cc4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-08T12:58:48.968569Z",
     "start_time": "2025-11-08T12:58:40.840367Z"
    }
   },
   "source": [
    "\n",
    "from pathlib import Path\n",
    "root = Path(ROOT)\n",
    "train_dir = root / \"training\"\n",
    "val_dir   = root / \"validation\"\n",
    "test_dir  = root / \"test\"\n",
    "for d in [train_dir, val_dir, test_dir]:\n",
    "    assert d.exists(), f\"Missing split directory: {d}\"\n",
    "\n",
    "train_ds = NCarsEventsGraphDataset1(str(train_dir), r=RADIUS, d_max=D_MAX,\n",
    "                                    n_samples=N_SAMPLES, sampling=SAMPLING, cache=False)\n",
    "val_ds   = NCarsEventsGraphDataset1(str(val_dir),   r=RADIUS, d_max=D_MAX,\n",
    "                                    n_samples=N_SAMPLES, sampling=SAMPLING, cache=False)\n",
    "test_ds  = NCarsEventsGraphDataset1(str(test_dir),  r=RADIUS, d_max=D_MAX,\n",
    "                                    n_samples=N_SAMPLES, sampling=SAMPLING, cache=False)\n",
    "\n",
    "from torch.utils.data import Subset\n",
    "def take_first(ds, n):\n",
    "    return Subset(ds, list(range(min(n, len(ds))))) if n and len(ds) > n else ds\n",
    "\n",
    "if LIMIT_PER_SPLIT and LIMIT_PER_SPLIT > 0:\n",
    "    train_ds = take_first(train_ds, LIMIT_PER_SPLIT)\n",
    "    val_ds   = take_first(val_ds, LIMIT_PER_SPLIT)\n",
    "    test_ds  = take_first(test_ds, LIMIT_PER_SPLIT)\n",
    "\n",
    "print(f\"Datasets ready: train={len(train_ds)} val={len(val_ds)} test={len(test_ds)}\")\n",
    "\n",
    "# Peek a few samples\n",
    "for i in range(min(3, len(train_ds))):\n",
    "    d = train_ds[i]\n",
    "    print(f\"[train {i}] x={tuple(d.x.shape)} pos={tuple(d.pos.shape)} ei={tuple(d.edge_index.shape)} \"\n",
    "          f\"ea={tuple(d.edge_attr.shape)} y={d.y.item()}\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datasets ready: train=20 val=20 test=20\n",
      "[train 0] x=(6263, 1) pos=(6263, 3) ei=(2, 190656) ea=(190656, 3) y=1\n",
      "[train 1] x=(3250, 1) pos=(3250, 3) ei=(2, 66166) ea=(66166, 3) y=1\n",
      "[train 2] x=(582, 1) pos=(582, 3) ei=(2, 3757) ea=(3757, 3) y=1\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "id": "c53c471e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-08T12:58:49.391132Z",
     "start_time": "2025-11-08T12:58:49.004315Z"
    }
   },
   "source": [
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=8, shuffle=True,  num_workers=0)\n",
    "val_loader   = DataLoader(val_ds,   batch_size=8, shuffle=False, num_workers=0)\n",
    "test_loader  = DataLoader(test_ds,  batch_size=1, shuffle=False, num_workers=0)\n",
    "\n",
    "batch = next(iter(train_loader))\n",
    "print(\"Batch:\")\n",
    "print(\"  x   :\", tuple(batch.x.shape))\n",
    "print(\"  pos :\", tuple(batch.pos.shape))\n",
    "print(\"  ei  :\", tuple(batch.edge_index.shape))\n",
    "print(\"  ea  :\", tuple(batch.edge_attr.shape))\n",
    "print(\"  y   :\", tuple(batch.y.shape))\n",
    "print(\"  batch vector:\", tuple(batch.batch.shape))\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch:\n",
      "  x   : (23058, 1)\n",
      "  pos : (23058, 3)\n",
      "  ei  : (2, 649697)\n",
      "  ea  : (649697, 3)\n",
      "  y   : (8,)\n",
      "  batch vector: (23058,)\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "id": "814bb42d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-08T12:58:49.596651Z",
     "start_time": "2025-11-08T12:58:49.440226Z"
    }
   },
   "source": [
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import SplineConv, global_mean_pool\n",
    "\n",
    "GRAPHRES_IMPORTED = False\n",
    "try:\n",
    "    from GraphRes import GraphRes\n",
    "    GRAPHRES_IMPORTED = True\n",
    "    print(\"✅ Imported GraphRes from your project\")\n",
    "except Exception as e:\n",
    "    print(\"⚠️  Could not import GraphRes, using minimal fallback. Reason:\", repr(e))\n",
    "\n",
    "class MinimalGraphRes(nn.Module):\n",
    "    def __init__(self, hidden=64, num_classes=2):\n",
    "        super().__init__()\n",
    "        self.conv1 = SplineConv(1, hidden, dim=3, kernel_size=5, aggr='mean')\n",
    "        self.bn1   = nn.BatchNorm1d(hidden)\n",
    "        self.conv2 = SplineConv(hidden, hidden, dim=3, kernel_size=5, aggr='mean')\n",
    "        self.bn2   = nn.BatchNorm1d(hidden)\n",
    "        self.fc    = nn.Linear(hidden, num_classes)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x = F.elu(self.conv1(data.x, data.edge_index, data.edge_attr)); x = self.bn1(x)\n",
    "        x = F.elu(self.conv2(x, data.edge_index, data.edge_attr));      x = self.bn2(x)\n",
    "        batch = getattr(data, \"batch\", None)\n",
    "        if batch is None:\n",
    "            batch = torch.zeros(x.size(0), dtype=torch.long, device=x.device)\n",
    "        z = global_mean_pool(x, batch)\n",
    "        return self.fc(z)\n",
    "\n",
    "if GRAPHRES_IMPORTED:\n",
    "    import torch\n",
    "    input_shape = torch.tensor([120, 100, 3])\n",
    "    model = GraphRes(dataset=\"ncars\", input_shape=input_shape, num_outputs=2,\n",
    "                     pooling_size=(16,12), bias=False, root_weight=False).to(DEVICE)\n",
    "else:\n",
    "    model = MinimalGraphRes(hidden=64, num_classes=2).to(DEVICE)\n",
    "\n",
    "print(model.__class__.__name__, \"on\", DEVICE)\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Imported GraphRes from your project\n",
      "GraphRes on cpu\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "id": "2e3a7439",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-08T13:01:01.240246Z",
     "start_time": "2025-11-08T12:58:49.643761Z"
    }
   },
   "source": [
    "\n",
    "model.eval()\n",
    "b = next(iter(train_loader)).to(DEVICE)\n",
    "with torch.no_grad():\n",
    "    out = model(b)\n",
    "print(\"Logits shape:\", tuple(out.shape))\n"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hanne\\anaconda3\\envs\\AEGNN\\lib\\site-packages\\torch_geometric\\nn\\conv\\spline_conv.py:133: UserWarning: We do not recommend using the non-optimized CPU version of `SplineConv`. If possible, please move your data to GPU.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logits shape: (8, 2)\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "id": "77fb9e9f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-08T13:29:45.968544Z",
     "start_time": "2025-11-08T13:01:01.377277Z"
    }
   },
   "source": [
    "\n",
    "crit = nn.CrossEntropyLoss()\n",
    "opt  = torch.optim.Adam(model.parameters(), lr=1e-3, weight_decay=0)\n",
    "\n",
    "def run_epoch(loader, train=False):\n",
    "    (model.train() if train else model.eval())\n",
    "    tot, correct, loss_sum = 0, 0, 0.0\n",
    "    for batch in loader:\n",
    "        batch = batch.to(DEVICE)\n",
    "        out = model(batch)\n",
    "        loss = crit(out, batch.y.view(-1))\n",
    "        if train:\n",
    "            opt.zero_grad(); loss.backward(); opt.step()\n",
    "        loss_sum += float(loss.item()) * batch.num_graphs\n",
    "        tot += batch.num_graphs\n",
    "        correct += int((out.argmax(-1) == batch.y.view(-1)).sum())\n",
    "    return loss_sum/max(tot,1), correct/max(tot,1)\n",
    "\n",
    "tr_loss, tr_acc = run_epoch(train_loader, train=True)\n",
    "va_loss, va_acc = run_epoch(val_loader,   train=False)\n",
    "print(f\"Epoch 1 | train {tr_loss:.4f}/{tr_acc:.3f} | val {va_loss:.4f}/{va_acc:.3f}\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 | train 1.3650/0.600 | val 0.6932/0.650\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "id": "6f5db2b7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-08T13:29:49.440108Z",
     "start_time": "2025-11-08T13:29:46.260214Z"
    }
   },
   "source": [
    "\n",
    "USE_ASYNC = True\n",
    "if USE_ASYNC:\n",
    "    try:\n",
    "        from torch_geometric.transforms import Cartesian\n",
    "        from aegnn.asyncronous import make_model_asynchronous\n",
    "        edge_attr_tf = Cartesian(cat=False, max_value=10.0)\n",
    "        model = make_model_asynchronous(model, RADIUS, [120, 100], edge_attr_tf).to(DEVICE)\n",
    "        print(\"✅ AEGNN async enabled\")\n",
    "    except Exception as e:\n",
    "        print(\"ℹ️  Async wrap skipped or failed (okay for this check):\", repr(e))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ AEGNN async enabled\n",
      "Post-async/test forward OK, logits: (1, 2)\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2025-11-08T13:29:49.450575Z"
    }
   },
   "cell_type": "code",
   "source": "\n",
   "id": "d2a3a7b023d68a9e",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
