{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7f84d5b8",
   "metadata": {},
   "source": [
    "\n",
    "# NCars Event-GNN Training (SAGE/GCN) â€” with AEGNN Async Eval\n",
    "\n",
    "- Loads NCars sequences from `{train, validation, test}`\n",
    "- Builds k-NN graphs in (x, y, t)\n",
    "- Trains a **SAGE** or **GCN** encoder + classifier head\n",
    "- Optionally wraps the **encoder only** with `AEGNNAsyncWrapper` for asynchronous evaluation\n",
    "- Lets us limit the number of sequences per split for quick tests\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "4b54b865",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-08T10:53:54.478460Z",
     "start_time": "2025-11-08T10:53:54.462708Z"
    }
   },
   "source": [
    "\n",
    "# data folder containing 'training/', 'validation/', 'test/'\n",
    "DATA = r\"C:\\Users\\hanne\\Documents\\Hannes\\Uni\\Maastricht\\Project\\GNNBenchmark\\src\\Models\\AEGNN\\data\\ncars\"\n",
    "\n",
    "# If events file has a specific name (else the dataset will auto-pick the first *.txt != is_car.txt)\n",
    "EVENTS_NAME = None  # should be \"events.txt\"\n",
    "\n",
    "# Sensor width,height (string \"W,H\") or None to normalize per-sequence\n",
    "SENSOR_WH = \"304,240\"  # or None\n",
    "\n",
    "# Graph building\n",
    "K = 8\n",
    "MAX_EVENTS = 1000  # reduce (e.g., 1000) for faster first run\n",
    "\n",
    "# Model\n",
    "MODEL = \"sage\"     # \"sage\" or \"gcn\"\n",
    "HIDDEN = 64\n",
    "DROPOUT = 0.2\n",
    "\n",
    "# Training\n",
    "EPOCHS = 15\n",
    "BATCH_SIZE = 32\n",
    "LR = 1e-3\n",
    "WD = 0.0\n",
    "\n",
    "# Use only first N (20) sequences per split (0 = all), for quick testing\n",
    "LIMIT_PER_SPLIT = 100\n",
    "\n",
    "# Async encoder wrapping at evaluation\n",
    "ASYNC_EVAL = True\n"
   ],
   "outputs": [],
   "execution_count": 18
  },
  {
   "cell_type": "code",
   "id": "228e5683",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-08T10:53:54.571266Z",
     "start_time": "2025-11-08T10:53:54.555442Z"
    }
   },
   "source": [
    "\n",
    "import sys, os, pathlib\n",
    "project_root_candidates = [\n",
    "    pathlib.Path.cwd(),                                  # current directory\n",
    "    pathlib.Path.cwd().parents[0],                       # 1 level up\n",
    "    pathlib.Path.cwd().parents[1],                       # 2 levels up\n",
    "]\n",
    "for pr in project_root_candidates:\n",
    "    if str(pr) not in sys.path:\n",
    "        sys.path.append(str(pr))\n",
    "\n",
    "from pathlib import Path\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import Adam\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.loader import DataLoader\n",
    "\n",
    "# moduls needed\n",
    "from ProcessNCars import NCarsEventsGraphDataset\n",
    "from GCNEncoder import GCNEncoder\n",
    "from SAGEEncoder import SAGEEncoder\n",
    "from FullModel_GCN_SAGE import FullModel, ClassifierHead\n",
    "from train_ncars_from_events import train_one_epoch, evaluate, take_first\n",
    "from ProcessNCars1 import NCarsEventsGraphDataset1"
   ],
   "outputs": [],
   "execution_count": 19
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#",
   "id": "f76c52149287f5fe"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Data Loading\n",
   "id": "cf7d83fc1bef5461"
  },
  {
   "cell_type": "code",
   "id": "098c1897",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-08T10:54:04.666787Z",
     "start_time": "2025-11-08T10:53:54.618544Z"
    }
   },
   "source": [
    "# dataset setup\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "sensor_wh = None\n",
    "if SENSOR_WH:\n",
    "    w, h = [int(s.strip()) for s in SENSOR_WH.split(\",\")]\n",
    "    sensor_wh = (w, h)\n",
    "\n",
    "root = Path(DATA)\n",
    "train_dir = root / \"training\"#change to your data path\n",
    "val_dir   = root / \"validation\"\n",
    "test_dir  = root / \"test\"\n",
    "for d in [train_dir, val_dir, test_dir]:\n",
    "    assert d.exists(), f\"Missing split directory: {d}\"\n",
    "\n",
    "precompute_gcn = (MODEL == \"gcn\")\n",
    "\n",
    "train_ds = NCarsEventsGraphDataset1(str(train_dir), EVENTS_NAME, K, MAX_EVENTS,\n",
    "                                   sensor_wh, precompute_gcn)\n",
    "val_ds   = NCarsEventsGraphDataset1(str(val_dir),   EVENTS_NAME, K, MAX_EVENTS,\n",
    "                                   sensor_wh, precompute_gcn)\n",
    "test_ds  = NCarsEventsGraphDataset1(str(test_dir),  EVENTS_NAME, K, MAX_EVENTS,\n",
    "                                   sensor_wh, precompute_gcn)\n",
    "\n",
    "# Limit for quick runs and testing\n",
    "if LIMIT_PER_SPLIT and LIMIT_PER_SPLIT > 0:\n",
    "    train_ds = take_first(train_ds, LIMIT_PER_SPLIT)\n",
    "    val_ds   = take_first(val_ds, LIMIT_PER_SPLIT)\n",
    "    # Uncomment to also limit test set:\n",
    "    test_ds  = take_first(test_ds, LIMIT_PER_SPLIT)\n",
    "\n",
    "print(\"Datasets ready.\",\n",
    "      \"\\n  train:\", len(train_ds),\n",
    "      \"\\n  val:  \", len(val_ds),\n",
    "      \"\\n  test: \", len(test_ds))\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datasets ready. \n",
      "  train: 100 \n",
      "  val:   100 \n",
      "  test:  100\n"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Model, Loaders, Optimizer\n",
   "id": "9d9c75a301cec04"
  },
  {
   "cell_type": "code",
   "id": "3525e3b5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-08T10:54:04.853241Z",
     "start_time": "2025-11-08T10:54:04.778007Z"
    }
   },
   "source": [
    "# model\n",
    "sample: Data = train_ds[0]\n",
    "in_ch = sample.x.size(-1)\n",
    "num_classes = int(max(sample.y.max().item(), 1) + 1)\n",
    "\n",
    "if MODEL == \"sage\":\n",
    "    encoder = SAGEEncoder(in_ch, hid=HIDDEN)\n",
    "else:\n",
    "    encoder = GCNEncoder(in_ch, hid=HIDDEN)\n",
    "\n",
    "head = ClassifierHead(hid=HIDDEN, num_classes=num_classes, dropout=DROPOUT, bias=True)\n",
    "model = FullModel(encoder, head).to(device)\n",
    "\n",
    "# loaders\n",
    "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader   = DataLoader(val_ds,   batch_size=BATCH_SIZE, shuffle=False)\n",
    "test_loader  = DataLoader(test_ds,  batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "# Optimizer & loss\n",
    "opt = Adam(model.parameters(), lr=LR, weight_decay=WD)\n",
    "crit = nn.CrossEntropyLoss()\n",
    "\n",
    "print(model)\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FullModel(\n",
      "  (encoder): SAGEEncoder(\n",
      "    (c1): SAGEConv(1, 64, aggr=mean)\n",
      "    (c2): SAGEConv(64, 64, aggr=mean)\n",
      "  )\n",
      "  (head): ClassifierHead(\n",
      "    (fc): Linear(in_features=64, out_features=2, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Training Loop",
   "id": "e3462885d7bc6854"
  },
  {
   "cell_type": "code",
   "id": "56e995f3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-08T10:54:49.353728Z",
     "start_time": "2025-11-08T10:54:04.868328Z"
    }
   },
   "source": [
    "\n",
    "#training loop\n",
    "best_val, best_state = 0.0, None\n",
    "for epoch in range(1, EPOCHS + 1):\n",
    "    tr_loss, tr_acc = train_one_epoch(model, train_loader, device, opt, crit)\n",
    "    va_loss, va_acc = evaluate(model, val_loader, device, crit)\n",
    "    if va_acc > best_val:\n",
    "        best_val = va_acc\n",
    "        best_state = {k: v.detach().cpu() for k, v in model.state_dict().items()}\n",
    "    print(f\"Epoch {epoch:03d} | train {tr_loss:.4f}/{tr_acc:.3f} | val {va_loss:.4f}/{va_acc:.3f}\")\n",
    "\n",
    "if best_state:\n",
    "    model.load_state_dict(best_state)\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 001 | train 0.7003/0.490 | val 0.6937/0.490\n",
      "Epoch 002 | train 0.6890/0.560 | val 0.6918/0.560\n",
      "Epoch 003 | train 0.6916/0.570 | val 0.6922/0.560\n",
      "Epoch 004 | train 0.6919/0.500 | val 0.6940/0.480\n",
      "Epoch 005 | train 0.6948/0.520 | val 0.6938/0.480\n",
      "Epoch 006 | train 0.6911/0.560 | val 0.6936/0.480\n",
      "Epoch 007 | train 0.6954/0.530 | val 0.6919/0.510\n",
      "Epoch 008 | train 0.6857/0.560 | val 0.6908/0.570\n",
      "Epoch 009 | train 0.6902/0.550 | val 0.6895/0.570\n",
      "Epoch 010 | train 0.6892/0.530 | val 0.6889/0.560\n",
      "Epoch 011 | train 0.6971/0.550 | val 0.6888/0.540\n",
      "Epoch 012 | train 0.6899/0.580 | val 0.6901/0.570\n",
      "Epoch 013 | train 0.6897/0.590 | val 0.6910/0.550\n",
      "Epoch 014 | train 0.6917/0.540 | val 0.6921/0.520\n",
      "Epoch 015 | train 0.6866/0.560 | val 0.6918/0.520\n"
     ]
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Asynchronous Evaluation",
   "id": "daf32dd2e0157dc"
  },
  {
   "cell_type": "code",
   "id": "9c7ba40e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-08T10:54:49.477276Z",
     "start_time": "2025-11-08T10:54:49.450489Z"
    }
   },
   "source": [
    "\n",
    "\n",
    "# async for evaluation, only part taken from AEGNN\n",
    "if ASYNC_EVAL:\n",
    "    try:\n",
    "        from AEGNNwrapper import AEGNNAsyncWrapper\n",
    "        enc_async = AEGNNAsyncWrapper(model.encoder)\n",
    "        print(\"[AEGNN] is_async=\", getattr(enc_async, \"is_async\", False),\n",
    "              \"| why_not=\", getattr(enc_async, \"why_not_async\", None))\n",
    "        model.encoder = enc_async.to(device)\n",
    "    except Exception as e:\n",
    "        print(\"[AEGNN] Wrapper import failed; continuing without async. Reason:\", repr(e))\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[AEGNN] is_async= True | why_not= None\n"
     ]
    }
   ],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-08T10:54:52.399984Z",
     "start_time": "2025-11-08T10:54:49.542770Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from tqdm import tqdm  # pip install tqdm (optional); else replace with a simple loop\n",
    "bad = []\n",
    "for i in range(len(test_ds)):\n",
    "    try:\n",
    "        _ = test_ds[i]\n",
    "    except Exception as e:\n",
    "        bad.append((i, str(test_ds.seq_dirs[i]), repr(e)))\n",
    "        print(\"BAD:\", i, test_ds.seq_dirs[i], e)\n",
    "\n",
    "print(\"bad count:\", len(bad))\n",
    "if bad:\n",
    "    print(\"examples:\", bad[:5])\n"
   ],
   "id": "9cbbe2347c47d1c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bad count: 0\n"
     ]
    }
   ],
   "execution_count": 24
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Testing\n",
   "id": "dbc1c976fa1c7708"
  },
  {
   "cell_type": "code",
   "id": "d2526355",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-08T10:55:43.298334Z",
     "start_time": "2025-11-08T10:55:42.523485Z"
    }
   },
   "source": [
    "# test\n",
    "te_loss, te_acc = evaluate(model, test_loader, device, crit)\n",
    "print(f\"Test  | loss {te_loss:.4f} acc {te_acc:.3f}\")"
   ],
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'SAGEConv' object has no attribute 'weight'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[26], line 2\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;66;03m# test\u001B[39;00m\n\u001B[1;32m----> 2\u001B[0m te_loss, te_acc \u001B[38;5;241m=\u001B[39m \u001B[43mevaluate\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtest_loader\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdevice\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcrit\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m      3\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mTest  | loss \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mte_loss\u001B[38;5;132;01m:\u001B[39;00m\u001B[38;5;124m.4f\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m acc \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mte_acc\u001B[38;5;132;01m:\u001B[39;00m\u001B[38;5;124m.3f\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\AEGNN\\lib\\site-packages\\torch\\utils\\_contextlib.py:116\u001B[0m, in \u001B[0;36mcontext_decorator.<locals>.decorate_context\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    113\u001B[0m \u001B[38;5;129m@functools\u001B[39m\u001B[38;5;241m.\u001B[39mwraps(func)\n\u001B[0;32m    114\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21mdecorate_context\u001B[39m(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[0;32m    115\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m ctx_factory():\n\u001B[1;32m--> 116\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m func(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\Documents\\Hannes\\Uni\\Maastricht\\Project\\GNNBenchmark\\src\\Models\\AEGNN\\train_ncars_from_events.py:55\u001B[0m, in \u001B[0;36mevaluate\u001B[1;34m(model, loader, device, crit)\u001B[0m\n\u001B[0;32m     53\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m data \u001B[38;5;129;01min\u001B[39;00m loader:\n\u001B[0;32m     54\u001B[0m     data \u001B[38;5;241m=\u001B[39m data\u001B[38;5;241m.\u001B[39mto(device)\n\u001B[1;32m---> 55\u001B[0m     logits \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     56\u001B[0m     loss \u001B[38;5;241m=\u001B[39m crit(logits, data\u001B[38;5;241m.\u001B[39my\u001B[38;5;241m.\u001B[39mview(\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m)\u001B[38;5;241m.\u001B[39mlong())\n\u001B[0;32m     57\u001B[0m     total \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m data\u001B[38;5;241m.\u001B[39mnum_graphs\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\AEGNN\\lib\\site-packages\\torch\\nn\\modules\\module.py:1553\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1551\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[0;32m   1552\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1553\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\AEGNN\\lib\\site-packages\\torch\\nn\\modules\\module.py:1562\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1557\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1558\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1559\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1560\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1561\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1562\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1564\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m   1565\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[1;32m~\\Documents\\Hannes\\Uni\\Maastricht\\Project\\GNNBenchmark\\src\\Models\\AEGNN\\FullModel_GCN_SAGE.py:29\u001B[0m, in \u001B[0;36mFullModel.forward\u001B[1;34m(self, data)\u001B[0m\n\u001B[0;32m     28\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, data: Data):\n\u001B[1;32m---> 29\u001B[0m     z \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mencoder\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     30\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhead(z)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\AEGNN\\lib\\site-packages\\torch\\nn\\modules\\module.py:1553\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1551\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[0;32m   1552\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1553\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\AEGNN\\lib\\site-packages\\torch\\nn\\modules\\module.py:1562\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1557\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1558\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1559\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1560\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1561\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1562\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1564\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m   1565\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[1;32m~\\Documents\\Hannes\\Uni\\Maastricht\\Project\\GNNBenchmark\\src\\Models\\AEGNN\\AEGNNwrapper.py:69\u001B[0m, in \u001B[0;36mAEGNNAsyncWrapper.forward\u001B[1;34m(self, data)\u001B[0m\n\u001B[0;32m     68\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, data: Data) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m torch\u001B[38;5;241m.\u001B[39mTensor:\n\u001B[1;32m---> 69\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_async_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\AEGNN\\lib\\site-packages\\torch\\nn\\modules\\module.py:1553\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1551\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[0;32m   1552\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1553\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\AEGNN\\lib\\site-packages\\torch\\nn\\modules\\module.py:1562\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1557\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1558\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1559\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1560\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1561\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1562\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1564\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m   1565\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[1;32m~\\Documents\\Hannes\\Uni\\Maastricht\\Project\\GNNBenchmark\\src\\Models\\AEGNN\\aegnn\\asyncronous\\__init__.py:86\u001B[0m, in \u001B[0;36mmake_model_asynchronous.<locals>.async_forward\u001B[1;34m(data, *args, **kwargs)\u001B[0m\n\u001B[0;32m     84\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21masync_forward\u001B[39m(data: torch_geometric\u001B[38;5;241m.\u001B[39mdata\u001B[38;5;241m.\u001B[39mData, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[0;32m     85\u001B[0m     module\u001B[38;5;241m.\u001B[39masy_pass_attribute(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124masy_pos\u001B[39m\u001B[38;5;124m'\u001B[39m, data\u001B[38;5;241m.\u001B[39mpos)\n\u001B[1;32m---> 86\u001B[0m     out \u001B[38;5;241m=\u001B[39m model_forward(data, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m     88\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m module\u001B[38;5;241m.\u001B[39masy_flops_log \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m     89\u001B[0m         flops_count \u001B[38;5;241m=\u001B[39m [compute_flops_from_module(layer) \u001B[38;5;28;01mfor\u001B[39;00m layer \u001B[38;5;129;01min\u001B[39;00m module\u001B[38;5;241m.\u001B[39m_modules\u001B[38;5;241m.\u001B[39mvalues()]\n",
      "File \u001B[1;32m~\\Documents\\Hannes\\Uni\\Maastricht\\Project\\GNNBenchmark\\src\\Models\\AEGNN\\SAGEEncoder.py:18\u001B[0m, in \u001B[0;36mSAGEEncoder.forward\u001B[1;34m(self, data)\u001B[0m\n\u001B[0;32m     16\u001B[0m x, ei \u001B[38;5;241m=\u001B[39m data\u001B[38;5;241m.\u001B[39mx, data\u001B[38;5;241m.\u001B[39medge_index\n\u001B[0;32m     17\u001B[0m batch \u001B[38;5;241m=\u001B[39m data\u001B[38;5;241m.\u001B[39mbatch \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(data, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mbatch\u001B[39m\u001B[38;5;124m\"\u001B[39m) \u001B[38;5;129;01mand\u001B[39;00m data\u001B[38;5;241m.\u001B[39mbatch \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m x\u001B[38;5;241m.\u001B[39mnew_zeros(x\u001B[38;5;241m.\u001B[39msize(\u001B[38;5;241m0\u001B[39m),                                                                                    dtype\u001B[38;5;241m=\u001B[39mtorch\u001B[38;5;241m.\u001B[39mlong)\n\u001B[1;32m---> 18\u001B[0m x \u001B[38;5;241m=\u001B[39m F\u001B[38;5;241m.\u001B[39mrelu(\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mc1\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mei\u001B[49m\u001B[43m)\u001B[49m)\n\u001B[0;32m     19\u001B[0m x \u001B[38;5;241m=\u001B[39m F\u001B[38;5;241m.\u001B[39mrelu(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mc2(x, ei))\n\u001B[0;32m     20\u001B[0m x \u001B[38;5;241m=\u001B[39m global_mean_pool(x, batch)  \u001B[38;5;66;03m# [B, hid]\u001B[39;00m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\AEGNN\\lib\\site-packages\\torch\\nn\\modules\\module.py:1553\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1551\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[0;32m   1552\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1553\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\AEGNN\\lib\\site-packages\\torch\\nn\\modules\\module.py:1562\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1557\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1558\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1559\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1560\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1561\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1562\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1564\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m   1565\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[1;32m~\\Documents\\Hannes\\Uni\\Maastricht\\Project\\GNNBenchmark\\src\\Models\\AEGNN\\aegnn\\asyncronous\\base\\base.py:18\u001B[0m, in \u001B[0;36mmake_asynchronous.<locals>.async_forward\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m     16\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21masync_forward\u001B[39m(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[0;32m     17\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m async_context(module, initialization_func, processing_func) \u001B[38;5;28;01mas\u001B[39;00m func:\n\u001B[1;32m---> 18\u001B[0m         output \u001B[38;5;241m=\u001B[39m func(module, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m     19\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m output\n",
      "File \u001B[1;32m~\\Documents\\Hannes\\Uni\\Maastricht\\Project\\GNNBenchmark\\src\\Models\\AEGNN\\aegnn\\asyncronous\\conv.py:110\u001B[0m, in \u001B[0;36m__graph_processing\u001B[1;34m(module, x, edge_index, edge_attr)\u001B[0m\n\u001B[0;32m    108\u001B[0m     phi \u001B[38;5;241m=\u001B[39m module\u001B[38;5;241m.\u001B[39mmessage(x_j, edge_attr\u001B[38;5;241m=\u001B[39medge_attr)\n\u001B[0;32m    109\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m--> 110\u001B[0m     x_j \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mmatmul(x_j, \u001B[43mmodule\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mweight\u001B[49m)\n\u001B[0;32m    111\u001B[0m     phi \u001B[38;5;241m=\u001B[39m module\u001B[38;5;241m.\u001B[39mmessage(x_j, edge_weight\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m)\n\u001B[0;32m    113\u001B[0m \u001B[38;5;66;03m# Use the internal message passing for feature aggregation.\u001B[39;00m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\AEGNN\\lib\\site-packages\\torch\\nn\\modules\\module.py:1729\u001B[0m, in \u001B[0;36mModule.__getattr__\u001B[1;34m(self, name)\u001B[0m\n\u001B[0;32m   1727\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m name \u001B[38;5;129;01min\u001B[39;00m modules:\n\u001B[0;32m   1728\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m modules[name]\n\u001B[1;32m-> 1729\u001B[0m \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mAttributeError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mtype\u001B[39m(\u001B[38;5;28mself\u001B[39m)\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m object has no attribute \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mname\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "\u001B[1;31mAttributeError\u001B[0m: 'SAGEConv' object has no attribute 'weight'"
     ]
    }
   ],
   "execution_count": 26
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
