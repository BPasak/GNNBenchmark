{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-16T12:34:45.866915Z",
     "start_time": "2026-01-16T12:34:45.819623Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "#Set hyperparameters\n",
    "\n",
    "epochs = 1000\n",
    "batch_size = 32 #optimal: 32\n",
    "lr = 5e-4\n",
    "dataset = 'ncars'  # 'ncars' or 'ncaltech'\n",
    "convType=\"fuse\" #fuse or ori_aegnn\n",
    "ncars_path = r'/Users/hannes/Documents/University/Datasets/raw_ncars/Prophesee_Dataset_n_cars'\n",
    "ncaltech_path =r'/Users/hannes/Documents/University/Datasets/raw_ncaltec'\n"
   ],
   "id": "f0621507aa270449",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# EvGNN Training Pipeline",
   "id": "8f4659774faa31d4"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-16T12:34:45.886726Z",
     "start_time": "2026-01-16T12:34:45.868324Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "\n",
    "import sys, os\n",
    "# Set MPS fallback BEFORE importing torch\n",
    "os.environ['PYTORCH_ENABLE_MPS_FALLBACK'] = '1'\n",
    "\n",
    "notebook_dir = os.getcwd()\n",
    "project_root = os.path.abspath(os.path.join(notebook_dir, '../src', '..'))\n",
    "src_path = os.path.join(project_root, 'src')\n",
    "if src_path not in sys.path:\n",
    "    sys.path.insert(0, src_path)\n",
    "if project_root not in sys.path:\n",
    "    sys.path.insert(0, project_root)\n",
    "# comment out if youre on windows and remove 'src.' prefixes from imports #\n",
    "\n",
    "from src.Datasets.batching import BatchManager\n",
    "\n",
    "import torch\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from torch.optim import AdamW\n",
    "\n"
   ],
   "id": "d4a6dda7ad2e755d",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Configuration: Device Selection",
   "id": "a0294216f1b527c4"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-16T12:34:45.909174Z",
     "start_time": "2026-01-16T12:34:45.888055Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Device options: 'auto', 'mps', 'cuda', 'cpu'\n",
    "USE_DEVICE = 'cpu'  # 'auto' = try MPS/CUDA first, fallback to CPU\n",
    "\n",
    "CPU_THREADS = 8\n",
    "# Apply settings\n",
    "torch.set_num_threads(CPU_THREADS)\n",
    "\n",
    "if USE_DEVICE == 'cpu':\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(f\"Using device: cpu with {CPU_THREADS} threads (forced)\")\n",
    "elif USE_DEVICE == 'mps':\n",
    "    if torch.backends.mps.is_available():\n",
    "        device = torch.device(\"mps\")\n",
    "        print(f\"Using device: mps (Apple Silicon GPU with CPU fallback for unsupported ops)\")\n",
    "        print(f\"CPU operations will use {CPU_THREADS} threads\")\n",
    "    else:\n",
    "        device = torch.device(\"cpu\")\n",
    "        print(f\"MPS not available, falling back to cpu with {CPU_THREADS} threads\")\n",
    "elif USE_DEVICE == 'cuda':\n",
    "    if torch.cuda.is_available():\n",
    "        device = torch.device(\"cuda\")\n",
    "        print(f\"Using device: cuda\")\n",
    "    else:\n",
    "        device = torch.device(\"cpu\")\n",
    "        print(f\"CUDA not available, falling back to cpu with {CPU_THREADS} threads\")\n",
    "else:  # 'auto'\n",
    "    if torch.backends.mps.is_available():\n",
    "        device = torch.device(\"mps\")\n",
    "        print(f\"Using device: mps (Apple Silicon GPU with CPU fallback)\")\n",
    "        print(f\"CPU operations will use {CPU_THREADS} threads\")\n",
    "    elif torch.cuda.is_available():\n",
    "        device = torch.device(\"cuda\")\n",
    "        print(f\"Using device: cuda\")\n",
    "    else:\n",
    "        device = torch.device(\"cpu\")\n",
    "        print(f\"Using device: cpu with {CPU_THREADS} threads\")"
   ],
   "id": "f5b15b3487409722",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu with 8 threads (forced)\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "cell_type": "markdown",
   "id": "b17db9cc",
   "metadata": {},
   "source": "# Dataset Selection"
  },
  {
   "cell_type": "code",
   "id": "aa36d870",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-16T12:34:45.922212Z",
     "start_time": "2026-01-16T12:34:45.909817Z"
    }
   },
   "source": [
    "from src.Datasets.ncaltech101 import NCaltech\n",
    "from src.Datasets.ncars import NCars\n",
    "if dataset == 'ncars':\n",
    "\n",
    "    num_classes = len(NCars.get_info().classes)\n",
    "    image_size = NCars.get_info().image_size\n",
    "elif dataset == 'ncaltech':\n",
    "\n",
    "    num_classes = len(NCaltech.get_info().classes)\n",
    "    image_size = NCaltech.get_info().image_size\n",
    "\n",
    "print(f\"Dataset: {dataset}\")\n",
    "print(f\"Number of classes: {num_classes}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: ncars\n",
      "Number of classes: 2\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "cell_type": "markdown",
   "id": "d03bc1f7f31c429",
   "metadata": {},
   "source": "# Model Setup"
  },
  {
   "cell_type": "code",
   "id": "37dbc3b654925cd3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-16T12:34:45.934127Z",
     "start_time": "2026-01-16T12:34:45.924397Z"
    }
   },
   "source": [
    "from src.Models.CleanEvGNN.recognition import RecognitionModel as EvGNN\n",
    "from torch_geometric.data import Data as PyGData\n",
    "\n",
    "img_shape_for_model = (image_size[1], image_size[0])  # Swap to (width, height)\n",
    "\n",
    "evgnn = EvGNN(\n",
    "    network=\"graph_res\",\n",
    "    dataset=dataset,\n",
    "    num_classes=num_classes,\n",
    "    img_shape=img_shape_for_model,\n",
    "    dim=3,\n",
    "    conv_type=convType,\n",
    "    distill=False\n",
    ").to(device)\n",
    "\n",
    "def transform_graph(graph: PyGData) -> PyGData:\n",
    "    return evgnn.data_transform(\n",
    "        graph, n_samples=10000, sampling=True,\n",
    "        beta=0.5e-5, radius=3.0, max_neighbors=16\n",
    "    ).to(device)"
   ],
   "outputs": [],
   "execution_count": 17
  },
  {
   "cell_type": "markdown",
   "id": "604f0ac3da13cf96",
   "metadata": {},
   "source": "# Dataset Loading"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-16T12:34:46.287529Z",
     "start_time": "2026-01-16T12:34:45.934541Z"
    }
   },
   "cell_type": "code",
   "source": [
    "if dataset == 'ncaltech':\n",
    "    dataset_obj = NCaltech(\n",
    "        root=ncaltech_path,\n",
    "        transform=transform_graph\n",
    "    )\n",
    "elif dataset == 'ncars':\n",
    "    dataset_obj = NCars(\n",
    "        root=ncars_path,\n",
    "        transform=transform_graph\n",
    "    )\n",
    "\n",
    "dataset_obj.process(modes=[\"training\"])\n",
    "num_training_samples = dataset_obj.get_mode_length(\"training\")\n",
    "print(f\"Training samples: {num_training_samples}\")\n",
    "\n",
    "training_set = BatchManager(\n",
    "    dataset=dataset_obj,\n",
    "    batch_size=batch_size,\n",
    "    mode=\"training\"\n",
    ")"
   ],
   "id": "9e49e5d5477304ea",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "training (cars):   0%|          | 0/7940 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "5847dea925d841dbbd6bb600b047a707"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "data": {
      "text/plain": [
       "training (background):   0%|          | 0/7482 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "075e3996ddfd4303a09eb3a7a6b6871f"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training samples: 13879\n"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Training Loop",
   "id": "623b1e8b72cec00e"
  },
  {
   "cell_type": "code",
   "id": "87b63308",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2026-01-16T12:34:46.288108Z"
    }
   },
   "source": [
    "\n",
    "\n",
    "\n",
    "optimizer = AdamW(evgnn.parameters(), lr=lr, weight_decay=1e-7)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=250, cooldown = 25)\n",
    "loss_fn = CrossEntropyLoss()\n",
    "\n",
    "print(\"Starting training...\")\n",
    "\n",
    "evgnn.train()\n",
    "losses = []\n",
    "\n",
    "for i in range(epochs):\n",
    "    optimizer.zero_grad()\n",
    "    examples = next(training_set)\n",
    "    reference = examples.y.to(device)\n",
    "\n",
    "    out = evgnn(examples)\n",
    "    loss = loss_fn(out, reference)\n",
    "\n",
    "    if torch.isnan(loss) or torch.isinf(loss):\n",
    "        print(f\"Loss is NaN/Inf at iteration {i}!\")\n",
    "        break\n",
    "\n",
    "    loss.backward()\n",
    "    torch.nn.utils.clip_grad_norm_(evgnn.parameters(), max_norm=1.0)\n",
    "    optimizer.step()\n",
    "    scheduler.step(loss.item())\n",
    "\n",
    "    losses.append(loss.item())\n",
    "\n",
    "    if i % 10 == 0:\n",
    "        with torch.no_grad():\n",
    "            predictions = out.argmax(dim=-1)\n",
    "            accuracy = (predictions == reference).float().mean().item()\n",
    "        print(f\"Iteration {i:4d} | Loss: {loss.item():.4f} | Acc: {accuracy:.3f}\")\n",
    "\n",
    "print(f\"\\nâœ… Training complete!\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n",
      "Iteration    0 | Loss: 0.8515 | Acc: 0.438\n",
      "Iteration   10 | Loss: 0.5086 | Acc: 0.750\n",
      "Iteration   20 | Loss: 0.5998 | Acc: 0.688\n",
      "Iteration   30 | Loss: 0.4926 | Acc: 0.750\n",
      "Iteration   40 | Loss: 0.5658 | Acc: 0.688\n",
      "Iteration   50 | Loss: 0.4542 | Acc: 0.781\n"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Save model in results directory\n",
    "os.makedirs('../results/TrainedModels', exist_ok=True)\n",
    "model_path = f'../results/TrainedModels/evgnn_{dataset}_{convType}.pth'\n",
    "torch.save(evgnn.state_dict(), model_path)\n",
    "print(f\"Model saved to: {model_path}\")"
   ],
   "id": "6c0e410ab138969c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Loss Visualization",
   "id": "94857c70c8f8b066"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(losses, alpha=0.3, color='blue', label='Raw loss')\n",
    "window = 50\n",
    "moving_mean = np.convolve(losses, np.ones(window)/window, mode='valid')\n",
    "plt.plot(range(window-1, len(losses)), moving_mean, color='orange', linewidth=2, label=f'Moving avg')\n",
    "plt.title(f'{dataset.upper()} Training Loss')\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Loss')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "id": "abb4c4fd5018f2d7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Test Evaluation",
   "id": "63dbb1cbaf2f956c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "dataset_obj.process(modes=[\"test\"])\n",
    "num_test_samples = dataset_obj.get_mode_length(\"test\")\n",
    "print(f\"Test samples: {num_test_samples}\")\n",
    "\n",
    "test_set = BatchManager(\n",
    "    dataset=dataset_obj,\n",
    "    batch_size=32,\n",
    "    mode=\"test\"\n",
    ")\n",
    "\n",
    "evgnn.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "print(\"Evaluating on test set...\")\n",
    "num_test_batches = (num_test_samples + 31) // 32\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i in range(num_test_batches):\n",
    "        examples = next(test_set)\n",
    "        reference = examples.y.to(device)\n",
    "        out = evgnn(examples)\n",
    "        predictions = out.argmax(dim=-1)\n",
    "\n",
    "        correct += (predictions == reference).sum().item()\n",
    "        total += reference.size(0)\n",
    "\n",
    "test_accuracy = correct / total\n",
    "print(f\"\\n{'='*50}\")\n",
    "print(f\"TEST ACCURACY: {test_accuracy:.4f} ({test_accuracy*100:.2f}%)\")\n",
    "print(f\"{'='*50}\")\n",
    "\n",
    "# Save results\n",
    "import json\n",
    "results = {\n",
    "    'dataset': dataset,\n",
    "    'architecture': 'fuse',\n",
    "    'test_accuracy': float(test_accuracy),\n",
    "    'num_test_samples': total\n",
    "}\n",
    "\n",
    "os.makedirs('results', exist_ok=True)\n",
    "with open(f'results/test_results_{dataset}orig_aegnn.json', 'w') as f:\n",
    "    json.dump(results, f, indent=2)\n",
    "\n",
    "print(f\"Results saved to: results/test_results_{dataset}_fuse.json\")\n"
   ],
   "id": "dd92e83548b57543",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GNNBenchmark",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
