{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-15T13:21:29.335485Z",
     "start_time": "2026-01-15T13:21:29.322386Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\"\"\"\n",
    "EvGNN Model Testing Notebook\n",
    "Load a trained model and evaluate on test dataset\n",
    "\"\"\"\n",
    "\n",
    "# ============================================================================\n",
    "# CONFIGURATION\n",
    "# ============================================================================\n",
    "\n",
    "# Model Configuration\n",
    "MODEL_NAME = 'evgnn_ncars_fuse.pth'  # Model file to load\n",
    "MODEL_PATH = '../results/TrainedModels'  # Path to trained models\n",
    "CONV_TYPE = \"fuse\"  # \"fuse\" or \"ori_aegnn\" - must match the trained model\n",
    "\n",
    "# Dataset Configuration\n",
    "DATASET = 'ncars'  # 'ncars' or 'ncaltech'\n",
    "NCARS_PATH = r'/Users/hannes/Documents/University/Datasets/raw_ncars/Prophesee_Dataset_n_cars'\n",
    "NCALTECH_PATH = r'/Users/hannes/Documents/University/Datasets/raw_ncaltech'\n",
    "\n",
    "# Test Configuration\n",
    "BATCH_SIZE = 32  # Batch size for testing\n",
    "N_SAMPLES = 10000  # Number of events to sample per recording\n",
    "BETA = 0.5e-5  # Time normalization\n",
    "RADIUS = 3.0  # Graph radius\n",
    "MAX_NEIGHBORS = 16  # Max neighbors in graph\n",
    "\n",
    "# Device Configuration\n",
    "USE_DEVICE = 'cpu'  # 'auto', 'mps', 'cuda', or 'cpu'\n",
    "CPU_THREADS = 8\n",
    "\n",
    "# Output Configuration\n",
    "SAVE_RESULTS = True  # Whether to save results to JSON\n",
    "RESULTS_DIR = '../results/sync_test_results'\n"
   ],
   "id": "ffd1606abac5a5a2",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-15T13:21:29.353861Z",
     "start_time": "2026-01-15T13:21:29.336164Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ============================================================================\n",
    "# SETUP\n",
    "# ============================================================================\n",
    "\n",
    "import sys, os\n",
    "import torch\n",
    "import json\n",
    "\n",
    "# Set MPS fallback BEFORE importing torch\n",
    "os.environ['PYTORCH_ENABLE_MPS_FALLBACK'] = '1'\n",
    "\n",
    "# Add project to path\n",
    "notebook_dir = os.getcwd()\n",
    "project_root = os.path.abspath(os.path.join(notebook_dir, '..'))\n",
    "src_path = os.path.join(project_root, 'src')\n",
    "if src_path not in sys.path:\n",
    "    sys.path.insert(0, src_path)\n",
    "if project_root not in sys.path:\n",
    "    sys.path.insert(0, project_root)\n",
    "\n",
    "from src.Datasets.batching import BatchManager\n",
    "from src.Datasets.ncaltech101 import NCaltech\n",
    "from src.Datasets.ncars import NCars\n",
    "from src.Models.CleanEvGNN.recognition import RecognitionModel as EvGNN\n",
    "from torch_geometric.data import Data as PyGData\n",
    "\n",
    "print(\"✓ Imports successful\")\n"
   ],
   "id": "9b97dc1e58ccfeea",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Imports successful\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-15T13:21:29.370092Z",
     "start_time": "2026-01-15T13:21:29.354442Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ============================================================================\n",
    "# DEVICE SETUP\n",
    "# ============================================================================\n",
    "\n",
    "torch.set_num_threads(CPU_THREADS)\n",
    "\n",
    "if USE_DEVICE == 'cpu':\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(f\"Using device: cpu with {CPU_THREADS} threads (forced)\")\n",
    "elif USE_DEVICE == 'mps':\n",
    "    if torch.backends.mps.is_available():\n",
    "        device = torch.device(\"mps\")\n",
    "        print(f\"Using device: mps (Apple Silicon GPU with CPU fallback for unsupported ops)\")\n",
    "        print(f\"CPU operations will use {CPU_THREADS} threads\")\n",
    "    else:\n",
    "        device = torch.device(\"cpu\")\n",
    "        print(f\"MPS not available, falling back to cpu with {CPU_THREADS} threads\")\n",
    "elif USE_DEVICE == 'cuda':\n",
    "    if torch.cuda.is_available():\n",
    "        device = torch.device(\"cuda\")\n",
    "        print(f\"Using device: cuda\")\n",
    "    else:\n",
    "        device = torch.device(\"cpu\")\n",
    "        print(f\"CUDA not available, falling back to cpu with {CPU_THREADS} threads\")\n",
    "else:  # 'auto'\n",
    "    if torch.backends.mps.is_available():\n",
    "        device = torch.device(\"mps\")\n",
    "        print(f\"Using device: mps (Apple Silicon GPU with CPU fallback)\")\n",
    "        print(f\"CPU operations will use {CPU_THREADS} threads\")\n",
    "    elif torch.cuda.is_available():\n",
    "        device = torch.device(\"cuda\")\n",
    "        print(f\"Using device: cuda\")\n",
    "    else:\n",
    "        device = torch.device(\"cpu\")\n",
    "        print(f\"Using device: cpu with {CPU_THREADS} threads\")\n"
   ],
   "id": "d6248fcd1f3bb1be",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu with 8 threads (forced)\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-15T13:21:29.381711Z",
     "start_time": "2026-01-15T13:21:29.370857Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ============================================================================\n",
    "# DATASET SETUP\n",
    "# ============================================================================\n",
    "\n",
    "# Get dataset info\n",
    "if DATASET == 'ncars':\n",
    "    num_classes = len(NCars.get_info().classes)\n",
    "    image_size = NCars.get_info().image_size\n",
    "    dataset_path = NCARS_PATH\n",
    "elif DATASET == 'ncaltech':\n",
    "    num_classes = len(NCaltech.get_info().classes)\n",
    "    image_size = NCaltech.get_info().image_size\n",
    "    dataset_path = NCALTECH_PATH\n",
    "else:\n",
    "    raise ValueError(f\"Unknown dataset: {DATASET}\")\n",
    "\n",
    "print(f\"\\nDataset: {DATASET}\")\n",
    "print(f\"Number of classes: {num_classes}\")\n",
    "print(f\"Image size: {image_size}\")\n"
   ],
   "id": "d482ead4233c2f89",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset: ncars\n",
      "Number of classes: 2\n",
      "Image size: (100, 120)\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-15T13:21:29.412028Z",
     "start_time": "2026-01-15T13:21:29.382402Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ============================================================================\n",
    "# MODEL SETUP\n",
    "# ============================================================================\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"LOADING MODEL\")\n",
    "print(f\"{'='*70}\")\n",
    "\n",
    "# Create model architecture\n",
    "img_shape_for_model = (image_size[1], image_size[0])  # Swap to (width, height)\n",
    "\n",
    "model = EvGNN(\n",
    "    network=\"graph_res\",\n",
    "    dataset=DATASET,\n",
    "    num_classes=num_classes,\n",
    "    img_shape=img_shape_for_model,\n",
    "    dim=3,\n",
    "    conv_type=CONV_TYPE,\n",
    "    distill=False\n",
    ").to(device)\n",
    "\n",
    "# Define transform function\n",
    "def transform_graph(graph: PyGData) -> PyGData:\n",
    "    return model.data_transform(\n",
    "        graph,\n",
    "        n_samples=N_SAMPLES,\n",
    "        sampling=True,\n",
    "        beta=BETA,\n",
    "        radius=RADIUS,\n",
    "        max_neighbors=MAX_NEIGHBORS\n",
    "    ).to(device)\n",
    "\n",
    "# Load trained weights\n",
    "model_full_path = os.path.join(MODEL_PATH, MODEL_NAME)\n",
    "if not os.path.exists(model_full_path):\n",
    "    raise FileNotFoundError(f\"Model not found: {model_full_path}\")\n",
    "\n",
    "print(f\"Loading model from: {model_full_path}\")\n",
    "model.load_state_dict(torch.load(model_full_path, map_location=device))\n",
    "model.eval()\n",
    "print(\"✓ Model loaded successfully\")\n",
    "print(f\"Architecture: {CONV_TYPE}\")\n",
    "print(f\"Parameters: {sum(p.numel() for p in model.parameters()):,}\")\n"
   ],
   "id": "85cb0912f6d1d361",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "LOADING MODEL\n",
      "======================================================================\n",
      "Loading model from: ../results/TrainedModels/evgnn_ncars_fuse.pth\n",
      "✓ Model loaded successfully\n",
      "Architecture: fuse\n",
      "Parameters: 6,608\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-15T13:21:29.496574Z",
     "start_time": "2026-01-15T13:21:29.412916Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ============================================================================\n",
    "# LOAD TEST DATASET\n",
    "# ============================================================================\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"LOADING TEST DATASET\")\n",
    "print(f\"{'='*70}\")\n",
    "\n",
    "# Create dataset with transform\n",
    "if DATASET == 'ncaltech':\n",
    "    dataset_obj = NCaltech(\n",
    "        root=dataset_path,\n",
    "        transform=transform_graph\n",
    "    )\n",
    "elif DATASET == 'ncars':\n",
    "    dataset_obj = NCars(\n",
    "        root=dataset_path,\n",
    "        transform=transform_graph\n",
    "    )\n",
    "\n",
    "# Process test set\n",
    "dataset_obj.process(modes=[\"test\"])\n",
    "num_test_samples = dataset_obj.get_mode_length(\"test\")\n",
    "print(f\"Test samples: {num_test_samples}\")\n",
    "\n",
    "# Create test data loader\n",
    "test_loader = BatchManager(\n",
    "    dataset=dataset_obj,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    mode=\"test\"\n",
    ")\n",
    "\n",
    "print(\"✓ Test dataset loaded\")\n"
   ],
   "id": "68dee291891a44b3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "LOADING TEST DATASET\n",
      "======================================================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "test (cars):   0%|          | 0/4396 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ee2bb7a707594b66a09cf1b70bcbb383"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "data": {
      "text/plain": [
       "test (background):   0%|          | 0/4211 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "449bd872dc6f48eaa009d7912a5134f5"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test samples: 8607\n",
      "✓ Test dataset loaded\n"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-15T13:22:15.778472Z",
     "start_time": "2026-01-15T13:21:29.500948Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ============================================================================\n",
    "# EVALUATE ON TEST SET\n",
    "# ============================================================================\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"EVALUATING ON TEST SET\")\n",
    "print(f\"{'='*70}\")\n",
    "\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "num_test_batches = (num_test_samples + BATCH_SIZE - 1) // BATCH_SIZE\n",
    "\n",
    "print(f\"Processing {num_test_batches} batches...\")\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch_idx in range(num_test_batches):\n",
    "        # Get batch\n",
    "        batch = next(test_loader)\n",
    "        targets = batch.y.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(batch)\n",
    "        predictions = outputs.argmax(dim=-1)\n",
    "\n",
    "        # Count correct predictions\n",
    "        correct += (predictions == targets).sum().item()\n",
    "        total += targets.size(0)\n",
    "\n",
    "        # Print progress every 10 batches\n",
    "        if (batch_idx + 1) % 10 == 0:\n",
    "            current_acc = correct / total\n",
    "            print(f\"  Batch {batch_idx + 1}/{num_test_batches} - \"\n",
    "                  f\"Accuracy so far: {current_acc:.4f} ({current_acc*100:.2f}%)\")\n",
    "\n",
    "# Calculate final accuracy\n",
    "test_accuracy = correct / total\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(f\"TEST RESULTS\")\n",
    "print(f\"{'='*70}\")\n",
    "print(f\"Total samples: {total}\")\n",
    "print(f\"Correct predictions: {correct}\")\n",
    "print(f\"Test Accuracy: {test_accuracy:.4f} ({test_accuracy*100:.2f}%)\")\n",
    "print(f\"{'='*70}\")\n"
   ],
   "id": "70b52dc19bbb2273",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "EVALUATING ON TEST SET\n",
      "======================================================================\n",
      "Processing 269 batches...\n",
      "  Batch 10/269 - Accuracy so far: 0.8469 (84.69%)\n",
      "  Batch 20/269 - Accuracy so far: 0.8547 (85.47%)\n",
      "  Batch 30/269 - Accuracy so far: 0.8594 (85.94%)\n",
      "  Batch 40/269 - Accuracy so far: 0.8617 (86.17%)\n",
      "  Batch 50/269 - Accuracy so far: 0.8656 (86.56%)\n",
      "  Batch 60/269 - Accuracy so far: 0.8641 (86.41%)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mKeyboardInterrupt\u001B[39m                         Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[19]\u001B[39m\u001B[32m, line 24\u001B[39m\n\u001B[32m     21\u001B[39m targets = batch.y.to(device)\n\u001B[32m     23\u001B[39m \u001B[38;5;66;03m# Forward pass\u001B[39;00m\n\u001B[32m---> \u001B[39m\u001B[32m24\u001B[39m outputs = \u001B[43mmodel\u001B[49m\u001B[43m(\u001B[49m\u001B[43mbatch\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     25\u001B[39m predictions = outputs.argmax(dim=-\u001B[32m1\u001B[39m)\n\u001B[32m     27\u001B[39m \u001B[38;5;66;03m# Count correct predictions\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/opt/anaconda3/envs/GNNBenchmark/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001B[39m, in \u001B[36mModule._call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1496\u001B[39m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[32m   1497\u001B[39m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[32m   1498\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m._backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_pre_hooks\n\u001B[32m   1499\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[32m   1500\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[32m-> \u001B[39m\u001B[32m1501\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1502\u001B[39m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[32m   1503\u001B[39m full_backward_hooks, non_full_backward_hooks = [], []\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Documents/GitHub/GNNBenchmark/src/Models/CleanEvGNN/recognition.py:66\u001B[39m, in \u001B[36mRecognitionModel.forward\u001B[39m\u001B[34m(self, data)\u001B[39m\n\u001B[32m     63\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, data: torch_geometric.data.Batch) -> torch.Tensor:\n\u001B[32m     64\u001B[39m     \u001B[38;5;66;03m# data.pos = data.pos[:, :self.dim]\u001B[39;00m\n\u001B[32m     65\u001B[39m     \u001B[38;5;66;03m# data.edge_attr = data.edge_attr[:, :self.dim]\u001B[39;00m\n\u001B[32m---> \u001B[39m\u001B[32m66\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m.\u001B[49m\u001B[43mforward\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Documents/GitHub/GNNBenchmark/src/Models/CleanEvGNN/GraphRes_Base.py:359\u001B[39m, in \u001B[36mGraphRes.forward\u001B[39m\u001B[34m(self, data, **kwargs)\u001B[39m\n\u001B[32m    357\u001B[39m     data.x = \u001B[38;5;28mself\u001B[39m.fuse2(x=data.x, pos=data.pos, edge_index=data.edge_index)\n\u001B[32m    358\u001B[39m     data.x = \u001B[38;5;28mself\u001B[39m.fuse3(x=data.x, pos=data.pos, edge_index=data.edge_index)\n\u001B[32m--> \u001B[39m\u001B[32m359\u001B[39m     data.x = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mfuse4\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m=\u001B[49m\u001B[43mdata\u001B[49m\u001B[43m.\u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpos\u001B[49m\u001B[43m=\u001B[49m\u001B[43mdata\u001B[49m\u001B[43m.\u001B[49m\u001B[43mpos\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43medge_index\u001B[49m\u001B[43m=\u001B[49m\u001B[43mdata\u001B[49m\u001B[43m.\u001B[49m\u001B[43medge_index\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    360\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m    361\u001B[39m     data.x = MyConvBNReLU.quant_tensor(data.x, scale=\u001B[38;5;28mself\u001B[39m.fuse1.x_scale, dtype=\u001B[38;5;28mself\u001B[39m.fuse1.f_dtype)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/opt/anaconda3/envs/GNNBenchmark/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001B[39m, in \u001B[36mModule._call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1496\u001B[39m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[32m   1497\u001B[39m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[32m   1498\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m._backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_pre_hooks\n\u001B[32m   1499\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[32m   1500\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[32m-> \u001B[39m\u001B[32m1501\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1502\u001B[39m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[32m   1503\u001B[39m full_backward_hooks, non_full_backward_hooks = [], []\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Documents/GitHub/GNNBenchmark/src/Models/CleanEvGNN/my_fuse.py:193\u001B[39m, in \u001B[36mMyConvBNReLU.forward\u001B[39m\u001B[34m(self, x, pos, edge_index)\u001B[39m\n\u001B[32m    188\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, x: Union[OptTensor, PairOptTensor],\n\u001B[32m    189\u001B[39m             pos: Union[Tensor, PairTensor], edge_index: Adj) -> Tensor:\n\u001B[32m    192\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m.fused:\n\u001B[32m--> \u001B[39m\u001B[32m193\u001B[39m         out_conv = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mpropagate\u001B[49m\u001B[43m(\u001B[49m\u001B[43medge_index\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mx\u001B[49m\u001B[43m=\u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpos\u001B[49m\u001B[43m=\u001B[49m\u001B[43mpos\u001B[49m\u001B[43m[\u001B[49m\u001B[43m:\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m:\u001B[49m\u001B[32;43m2\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msize\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[32m    194\u001B[39m         out_bn = \u001B[38;5;28mself\u001B[39m.bn(out_conv)\n\u001B[32m    195\u001B[39m         out = \u001B[38;5;28mself\u001B[39m.act(out_bn)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/var/folders/yp/cw81wcbs6gx_7w5jry003bj40000gn/T/Models.CleanEvGNN.my_fuse_MyConvBNReLU_propagate_tam6_rbv.py:251\u001B[39m, in \u001B[36mpropagate\u001B[39m\u001B[34m(self, edge_index, x, pos, size)\u001B[39m\n\u001B[32m    241\u001B[39m             kwargs = CollectArgs(\n\u001B[32m    242\u001B[39m                 x_j=kwargs.x_j,\n\u001B[32m    243\u001B[39m                 pos_i=kwargs.pos_i,\n\u001B[32m   (...)\u001B[39m\u001B[32m    247\u001B[39m                 dim_size=hook_kwargs[\u001B[33m'\u001B[39m\u001B[33mdim_size\u001B[39m\u001B[33m'\u001B[39m],\n\u001B[32m    248\u001B[39m             )\n\u001B[32m    249\u001B[39m \u001B[38;5;66;03m# End Aggregate Forward Pre Hook #######################################\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m251\u001B[39m out = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43maggregate\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    252\u001B[39m \u001B[43m    \u001B[49m\u001B[43mout\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    253\u001B[39m \u001B[43m    \u001B[49m\u001B[43mindex\u001B[49m\u001B[43m=\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m.\u001B[49m\u001B[43mindex\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    254\u001B[39m \u001B[43m    \u001B[49m\u001B[43mptr\u001B[49m\u001B[43m=\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m.\u001B[49m\u001B[43mptr\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    255\u001B[39m \u001B[43m    \u001B[49m\u001B[43mdim_size\u001B[49m\u001B[43m=\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m.\u001B[49m\u001B[43mdim_size\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    256\u001B[39m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    258\u001B[39m \u001B[38;5;66;03m# Begin Aggregate Forward Hook #########################################\u001B[39;00m\n\u001B[32m    259\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m torch.jit.is_scripting() \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m is_compiling():\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/opt/anaconda3/envs/GNNBenchmark/lib/python3.11/site-packages/torch_geometric/nn/conv/message_passing.py:594\u001B[39m, in \u001B[36mMessagePassing.aggregate\u001B[39m\u001B[34m(self, inputs, index, ptr, dim_size)\u001B[39m\n\u001B[32m    577\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34maggregate\u001B[39m(\n\u001B[32m    578\u001B[39m     \u001B[38;5;28mself\u001B[39m,\n\u001B[32m    579\u001B[39m     inputs: Tensor,\n\u001B[32m   (...)\u001B[39m\u001B[32m    582\u001B[39m     dim_size: Optional[\u001B[38;5;28mint\u001B[39m] = \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[32m    583\u001B[39m ) -> Tensor:\n\u001B[32m    584\u001B[39m \u001B[38;5;250m    \u001B[39m\u001B[33mr\u001B[39m\u001B[33;03m\"\"\"Aggregates messages from neighbors as\u001B[39;00m\n\u001B[32m    585\u001B[39m \u001B[33;03m    :math:`\\bigoplus_{j \\in \\mathcal{N}(i)}`.\u001B[39;00m\n\u001B[32m    586\u001B[39m \n\u001B[32m   (...)\u001B[39m\u001B[32m    592\u001B[39m \u001B[33;03m    as specified in :meth:`__init__` by the :obj:`aggr` argument.\u001B[39;00m\n\u001B[32m    593\u001B[39m \u001B[33;03m    \"\"\"\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m594\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43maggr_module\u001B[49m\u001B[43m(\u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mindex\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mptr\u001B[49m\u001B[43m=\u001B[49m\u001B[43mptr\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdim_size\u001B[49m\u001B[43m=\u001B[49m\u001B[43mdim_size\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    595\u001B[39m \u001B[43m                            \u001B[49m\u001B[43mdim\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mnode_dim\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/opt/anaconda3/envs/GNNBenchmark/lib/python3.11/site-packages/torch_geometric/experimental.py:117\u001B[39m, in \u001B[36mdisable_dynamic_shapes.<locals>.decorator.<locals>.wrapper\u001B[39m\u001B[34m(*args, **kwargs)\u001B[39m\n\u001B[32m    114\u001B[39m \u001B[38;5;129m@functools\u001B[39m.wraps(func)\n\u001B[32m    115\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mwrapper\u001B[39m(*args: Any, **kwargs: Any) -> Any:\n\u001B[32m    116\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m is_experimental_mode_enabled(\u001B[33m'\u001B[39m\u001B[33mdisable_dynamic_shapes\u001B[39m\u001B[33m'\u001B[39m):\n\u001B[32m--> \u001B[39m\u001B[32m117\u001B[39m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    119\u001B[39m     \u001B[38;5;28;01mfor\u001B[39;00m required_arg \u001B[38;5;129;01min\u001B[39;00m required_args:\n\u001B[32m    120\u001B[39m         index = required_args_pos[required_arg]\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/opt/anaconda3/envs/GNNBenchmark/lib/python3.11/site-packages/torch_geometric/nn/aggr/base.py:131\u001B[39m, in \u001B[36mAggregation.__call__\u001B[39m\u001B[34m(self, x, index, ptr, dim_size, dim, **kwargs)\u001B[39m\n\u001B[32m    128\u001B[39m     dim_size = \u001B[38;5;28mint\u001B[39m(index.max()) + \u001B[32m1\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m index.numel() > \u001B[32m0\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m \u001B[32m0\u001B[39m\n\u001B[32m    130\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m131\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m.\u001B[49m\u001B[34;43m__call__\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mindex\u001B[49m\u001B[43m=\u001B[49m\u001B[43mindex\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mptr\u001B[49m\u001B[43m=\u001B[49m\u001B[43mptr\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdim_size\u001B[49m\u001B[43m=\u001B[49m\u001B[43mdim_size\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    132\u001B[39m \u001B[43m                            \u001B[49m\u001B[43mdim\u001B[49m\u001B[43m=\u001B[49m\u001B[43mdim\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    133\u001B[39m \u001B[38;5;28;01mexcept\u001B[39;00m (\u001B[38;5;167;01mIndexError\u001B[39;00m, \u001B[38;5;167;01mRuntimeError\u001B[39;00m) \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[32m    134\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m index \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/opt/anaconda3/envs/GNNBenchmark/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001B[39m, in \u001B[36mModule._call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1496\u001B[39m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[32m   1497\u001B[39m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[32m   1498\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m._backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_pre_hooks\n\u001B[32m   1499\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[32m   1500\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[32m-> \u001B[39m\u001B[32m1501\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1502\u001B[39m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[32m   1503\u001B[39m full_backward_hooks, non_full_backward_hooks = [], []\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/opt/anaconda3/envs/GNNBenchmark/lib/python3.11/site-packages/torch_geometric/nn/aggr/basic.py:50\u001B[39m, in \u001B[36mMaxAggregation.forward\u001B[39m\u001B[34m(self, x, index, ptr, dim_size, dim)\u001B[39m\n\u001B[32m     47\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, x: Tensor, index: Optional[Tensor] = \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[32m     48\u001B[39m             ptr: Optional[Tensor] = \u001B[38;5;28;01mNone\u001B[39;00m, dim_size: Optional[\u001B[38;5;28mint\u001B[39m] = \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[32m     49\u001B[39m             dim: \u001B[38;5;28mint\u001B[39m = -\u001B[32m2\u001B[39m) -> Tensor:\n\u001B[32m---> \u001B[39m\u001B[32m50\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mreduce\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mindex\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mptr\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdim_size\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdim\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mreduce\u001B[49m\u001B[43m=\u001B[49m\u001B[33;43m'\u001B[39;49m\u001B[33;43mmax\u001B[39;49m\u001B[33;43m'\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/opt/anaconda3/envs/GNNBenchmark/lib/python3.11/site-packages/torch_geometric/nn/aggr/base.py:185\u001B[39m, in \u001B[36mAggregation.reduce\u001B[39m\u001B[34m(self, x, index, ptr, dim_size, dim, reduce)\u001B[39m\n\u001B[32m    182\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m index \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m    183\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\u001B[33m\"\u001B[39m\u001B[33mAggregation requires \u001B[39m\u001B[33m'\u001B[39m\u001B[33mindex\u001B[39m\u001B[33m'\u001B[39m\u001B[33m to be specified\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m--> \u001B[39m\u001B[32m185\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mscatter\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mindex\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdim\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdim_size\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mreduce\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/opt/anaconda3/envs/GNNBenchmark/lib/python3.11/site-packages/torch_geometric/utils/_scatter.py:98\u001B[39m, in \u001B[36mscatter\u001B[39m\u001B[34m(src, index, dim, dim_size, reduce)\u001B[39m\n\u001B[32m     96\u001B[39m index = broadcast(index, src, dim)\n\u001B[32m     97\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m is_in_onnx_export():\n\u001B[32m---> \u001B[39m\u001B[32m98\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43msrc\u001B[49m\u001B[43m.\u001B[49m\u001B[43mnew_zeros\u001B[49m\u001B[43m(\u001B[49m\u001B[43msize\u001B[49m\u001B[43m)\u001B[49m\u001B[43m.\u001B[49m\u001B[43mscatter_reduce_\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m     99\u001B[39m \u001B[43m        \u001B[49m\u001B[43mdim\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mindex\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msrc\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mreduce\u001B[49m\u001B[43m=\u001B[49m\u001B[33;43mf\u001B[39;49m\u001B[33;43m'\u001B[39;49m\u001B[33;43ma\u001B[39;49m\u001B[38;5;132;43;01m{\u001B[39;49;00m\u001B[43mreduce\u001B[49m\u001B[43m[\u001B[49m\u001B[43m-\u001B[49m\u001B[32;43m3\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m]\u001B[49m\u001B[38;5;132;43;01m}\u001B[39;49;00m\u001B[33;43m'\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m    100\u001B[39m \u001B[43m        \u001B[49m\u001B[43minclude_self\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[32m    102\u001B[39m fill = torch.full(  \u001B[38;5;66;03m# type: ignore\u001B[39;00m\n\u001B[32m    103\u001B[39m     size=(\u001B[32m1\u001B[39m, ),\n\u001B[32m    104\u001B[39m     fill_value=src.min() \u001B[38;5;28;01mif\u001B[39;00m \u001B[33m'\u001B[39m\u001B[33mmax\u001B[39m\u001B[33m'\u001B[39m \u001B[38;5;129;01min\u001B[39;00m reduce \u001B[38;5;28;01melse\u001B[39;00m src.max(),\n\u001B[32m    105\u001B[39m     dtype=src.dtype,\n\u001B[32m    106\u001B[39m     device=src.device,\n\u001B[32m    107\u001B[39m ).expand_as(src)\n\u001B[32m    108\u001B[39m out = src.new_zeros(size).scatter_reduce_(dim, index, fill,\n\u001B[32m    109\u001B[39m                                           reduce=\u001B[33mf\u001B[39m\u001B[33m'\u001B[39m\u001B[33ma\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mreduce[-\u001B[32m3\u001B[39m:]\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m'\u001B[39m,\n\u001B[32m    110\u001B[39m                                           include_self=\u001B[38;5;28;01mTrue\u001B[39;00m)\n",
      "\u001B[31mKeyboardInterrupt\u001B[39m: "
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# ============================================================================\n",
    "# SAVE RESULTS\n",
    "# ============================================================================\n",
    "\n",
    "if SAVE_RESULTS:\n",
    "    print(f\"\\nSaving results...\")\n",
    "\n",
    "    # Create results dictionary\n",
    "    results = {\n",
    "        'model_name': MODEL_NAME,\n",
    "        'dataset': DATASET,\n",
    "        'architecture': CONV_TYPE,\n",
    "        'test_accuracy': float(test_accuracy),\n",
    "        'num_test_samples': total,\n",
    "        'correct_predictions': correct,\n",
    "        'batch_size': BATCH_SIZE,\n",
    "        'configuration': {\n",
    "            'n_samples': N_SAMPLES,\n",
    "            'beta': BETA,\n",
    "            'radius': RADIUS,\n",
    "            'max_neighbors': MAX_NEIGHBORS\n",
    "        }\n",
    "    }\n",
    "\n",
    "    # Create results directory\n",
    "    os.makedirs(RESULTS_DIR, exist_ok=True)\n",
    "\n",
    "    # Save to JSON\n",
    "    result_filename = f'test_results_{DATASET}_{CONV_TYPE}.json'\n",
    "    result_path = os.path.join(RESULTS_DIR, result_filename)\n",
    "\n",
    "    with open(result_path, 'w') as f:\n",
    "        json.dump(results, f, indent=2)\n",
    "\n",
    "    print(f\"✓ Results saved to: {result_path}\")\n",
    "else:\n",
    "    print(\"\\nResults not saved (SAVE_RESULTS = False)\")\n",
    "\n",
    "print(\"\\n✓ Testing complete!\")\n"
   ],
   "id": "7be565639801b36d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "\n",
   "id": "d9fad810018832ac",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
