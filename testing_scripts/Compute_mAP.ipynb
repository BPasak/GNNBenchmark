{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Imports",
   "id": "722b940ed248ffe1"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2026-01-21T06:57:26.365279797Z",
     "start_time": "2026-01-21T06:57:24.202125495Z"
    }
   },
   "source": [
    "from pathlib import Path\n",
    "from typing import Literal\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from Datasets.base import DatasetMode\n",
    "from Datasets.batching import BatchManager\n",
    "from mean_average_precision import MetricBuilder"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/benio/miniconda3/envs/gnn-benchmarking/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Parameter Setup",
   "id": "27e569c07d704545"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-21T06:57:26.371320716Z",
     "start_time": "2026-01-21T06:57:26.365854121Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Choose an investigated dataset and model\n",
    "dataset_name: Literal[\"NCaltech101\", \"Gen1\"] = \"Gen1\"\n",
    "model_name: Literal[\"EGSST\", \"AEGNN\"] = \"EGSST\"\n",
    "\n",
    "# Set corresponding paths\n",
    "dataset_path: Path = Path(r\"/home/benio/Documents/Datasets/Gen1\")\n",
    "results_path: Path = Path(r\"../Results/Detection_EGSST_on_Gen1_1\")\n",
    "model_path: Path = results_path / \"TrainedModels\" / \"300.pth\"\n",
    "\n",
    "# mAP evaluation parameters\n",
    "batch_size: int = 2\n",
    "investigated_mode: DatasetMode = \"validation\"\n",
    "epoch_count: int = 50\n",
    "\n",
    "# Graph preprocessing parameters\n",
    "inference_event_count: int = 10000\n",
    "beta: float = 0.0001\n",
    "radius: float = 5.\n",
    "\n",
    "# EGSST specific parameters\n",
    "min_nodes_subgraph: int = 1000\n",
    "detection_head_config: Path = Path(r\"../confs/rtdtr_head_gen1.yml\")\n",
    "ecnn_flag: bool = True # Whether enhanced cnn should be used\n",
    "ti_flag: bool = True # Whether TAC augmentation should be used\n",
    "\n",
    "# AEGNN specific parameters\n",
    "kernel_size: int = 8\n",
    "pooling_outputs: int = 128\n",
    "max_neighbors: int = 32\n",
    "sampling: bool = True"
   ],
   "id": "8938e3f7d25ffd60",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Loading Dataset",
   "id": "656291fb700505e4"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-21T06:57:26.406691080Z",
     "start_time": "2026-01-21T06:57:26.371717347Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(f\"Loading {dataset_name} dataset...\")\n",
    "if dataset_name == \"Gen1\":\n",
    "    from Datasets.gen1 import Gen1\n",
    "    dataset = Gen1(\n",
    "        root=dataset_path,\n",
    "    )\n",
    "elif dataset_name == \"NCaltech101\":\n",
    "    from Datasets.ncaltech101 import NCaltech\n",
    "    dataset = NCaltech(\n",
    "        root=dataset_path,\n",
    "    )\n",
    "else:\n",
    "    raise ValueError(f\"Dataset {dataset_name} not implemented.\")\n",
    "\n",
    "dataset.process()\n",
    "print(f\"Dataset Initialized.\")\n",
    "\n",
    "batch_manager = BatchManager(\n",
    "    dataset = dataset,\n",
    "    batch_size = batch_size,\n",
    "    mode = investigated_mode\n",
    ")"
   ],
   "id": "c881c77e2ce09355",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Gen1 dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training (train_c): 100%|██████████| 250/250 [00:00<00:00, 148586.65it/s]\n",
      "validation (val_b): 100%|██████████| 179/179 [00:00<00:00, 200689.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Initialized.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Initializing Model",
   "id": "e13153d25f3e1ae4"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-21T06:57:27.159944266Z",
     "start_time": "2026-01-21T06:57:26.407861850Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(f\"Initializing {model_name} model...\")\n",
    "if model_name == \"EGSST\":\n",
    "    from Models.EGSST.EGSST import EGSST\n",
    "    model = EGSST(\n",
    "        dataset_information = dataset.get_info(),\n",
    "        detection_head_config = str(detection_head_config)\n",
    "    )\n",
    "\n",
    "    def transform_graph(graph):\n",
    "        graph = model.data_transform(\n",
    "            graph, beta = beta,\n",
    "            radius = radius,\n",
    "            min_nodes_subgraph = min_nodes_subgraph,\n",
    "            n_samples = inference_event_count,\n",
    "            sub_sample = sampling\n",
    "        )\n",
    "\n",
    "        if graph is None or graph.pos is None:\n",
    "            return None\n",
    "\n",
    "        if isinstance(graph.bbox, dict):\n",
    "            maximum_time = graph.pos[:, 2].max()\n",
    "            times_of_boxes = torch.tensor(list(graph.bbox.keys()))\n",
    "            time_diff = (times_of_boxes - maximum_time) ** 2\n",
    "            graph.bbox = graph.bbox[list(graph.bbox.keys())[time_diff.argmin()]]\n",
    "\n",
    "        return graph\n",
    "\n",
    "    graph_transform = transform_graph\n",
    "elif model_name == \"AEGNN\":\n",
    "    from Models.CleanAEGNN.AEGNN_Detection import AEGNN_Detection\n",
    "    num_classes = len(dataset.get_info().classes)\n",
    "    if dataset_name == \"Gen1\":\n",
    "        num_classes += 1\n",
    "    model = AEGNN_Detection(\n",
    "        input_shape = (*dataset.get_info().image_size, 3),\n",
    "        kernel_size = kernel_size,\n",
    "        n = [1, 16, 32, 32, 32, 128, 128, 128],\n",
    "        pooling_outputs = pooling_outputs,\n",
    "        num_classes = num_classes,\n",
    "    )\n",
    "\n",
    "    def transform_graph(graph):\n",
    "        graph = model.data_transform(\n",
    "            graph, n_samples = inference_event_count, sampling = sampling,\n",
    "            beta =  beta, radius = radius,\n",
    "            max_neighbors = max_neighbors\n",
    "        )\n",
    "\n",
    "        if isinstance(graph.bbox, dict):\n",
    "            maximum_time = graph.pos[:, 2].max()\n",
    "            times_of_boxes = torch.tensor(list(graph.bbox.keys()))\n",
    "            time_diff = (times_of_boxes - maximum_time) ** 2\n",
    "            graph.bbox = graph.bbox[list(graph.bbox.keys())[time_diff.argmin()]]\n",
    "\n",
    "        return graph\n",
    "\n",
    "    graph_transform = transform_graph\n",
    "else:\n",
    "    raise ValueError(f\"Model {model_name} not implemented.\")\n",
    "print(f\"Model Initialized.\")\n",
    "\n",
    "print(f\"Loading model from: {model_path}\")\n",
    "state_dict = torch.load(model_path, map_location=torch.device(\"cpu\"))\n",
    "model.load_state_dict(state_dict)\n",
    "print(\"Model Loaded.\")\n",
    "\n",
    "dataset.transform = graph_transform\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "print(f\"Using device: {device}\")"
   ],
   "id": "685b12e841285a08",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing EGSST model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/benio/Documents/GNNBenchmark/src/External/EGSST_PAPER/detector/efvit/nn/ops.py:570: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  @autocast(enabled=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Initialized.\n",
      "Loading model from: ../Results/Detection_EGSST_on_Gen1_1/TrainedModels/300.pth\n",
      "Model Loaded.\n",
      "Using device: cuda\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# mAP Computation",
   "id": "4fa2e250cd2cceb0"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-21T06:59:48.762576017Z",
     "start_time": "2026-01-21T06:57:27.517991952Z"
    }
   },
   "cell_type": "code",
   "source": [
    "metric_fn = MetricBuilder.build_evaluation_metric(\"map_2d\", async_mode=False, num_classes=len(dataset.get_info().classes))\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for epoch in tqdm(range(1, epoch_count + 1), total = epoch_count, desc = f\"Assessing mAP\"):\n",
    "        try:\n",
    "            batch = next(batch_manager)\n",
    "            batch = batch.to(device)\n",
    "            output = model(batch)\n",
    "\n",
    "            for i in range(batch.num_graphs):\n",
    "                graph_data = batch.get_example(i)\n",
    "                bbox = graph_data.bbox.detach().cpu().numpy()\n",
    "                gt_label = bbox[:, 0]\n",
    "                gt_x_min, gt_x_max = bbox[:, 1] - bbox[:, 3]/2, bbox[:, 1] + bbox[:, 3]/2\n",
    "                gt_y_min, gt_y_max = bbox[:, 2] - bbox[:, 4]/2, bbox[:, 2] + bbox[:, 4]/2\n",
    "                gt_bbox = np.concat(\n",
    "                    [\n",
    "                        gt_x_min[:, None],\n",
    "                        gt_y_min[:, None],\n",
    "                        gt_x_max[:, None],\n",
    "                        gt_y_max[:, None],\n",
    "                        gt_label[:, None],\n",
    "                        np.zeros_like(gt_label[:, None]),\n",
    "                        np.zeros_like(gt_label[:, None]),\n",
    "                    ],\n",
    "                    axis = 1\n",
    "                )\n",
    "\n",
    "                pred_boxes = output[i]\n",
    "                pred_boxes = torch.concat(\n",
    "                    [\n",
    "                        pred_boxes[\"boxes\"],\n",
    "                        pred_boxes[\"labels\"][:, None],\n",
    "                        pred_boxes[\"scores\"][:, None],\n",
    "                    ],\n",
    "                    dim = 1\n",
    "                ).detach().cpu().numpy()\n",
    "\n",
    "                metric_fn.add(pred_boxes, gt_bbox)\n",
    "        except Exception as e:\n",
    "            print(f\"Error occurred during epoch {epoch}. Skipping to next epoch.\")\n",
    "\n",
    "with open(results_path / \"mAP_results.txt\", \"w\") as f:\n",
    "    f.write(f\"MAP@0.9: {metric_fn.value(iou_thresholds = 0.9)['mAP']}\\n\")\n",
    "    f.write(f\"MAP@0.5: {metric_fn.value(iou_thresholds = 0.5)['mAP']}\\n\")\n",
    "    f.write(f\"MAP@0.25: {metric_fn.value(iou_thresholds = 0.25)['mAP']}\\n\")\n",
    "    f.write(f\"MAP@0.1: {metric_fn.value(iou_thresholds = 0.1)['mAP']}\\n\")\n",
    "    f.write(f\"MAP@0.05: {metric_fn.value(iou_thresholds = 0.05)['mAP']}\\n\")"
   ],
   "id": "e6439f2e2ed4735a",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Assessing mAP:   0%|          | 0/50 [00:00<?, ?it/s]/home/benio/miniconda3/envs/gnn-benchmarking/lib/python3.11/site-packages/mean_average_precision/mean_average_precision_2d.py:64: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  self.match_table[c] = pd.concat([self.match_table[c], match_table], axis=0, join='outer')\n",
      "Assessing mAP: 100%|██████████| 50/50 [02:21<00:00,  2.82s/it]\n"
     ]
    }
   ],
   "execution_count": 5
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
