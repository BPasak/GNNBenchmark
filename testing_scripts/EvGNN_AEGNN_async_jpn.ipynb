{
 "cells": [
  {
   "metadata": {},
   "cell_type": "raw",
   "source": "",
   "id": "25b78c1b23f12d28"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-20T16:21:00.708899645Z",
     "start_time": "2026-01-20T16:21:00.689291906Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Model Configuration\n",
    "CONV_TYPE = \"fuse\"  # \"ori_aegnn\" or \"fuse\"\n",
    "MODEL_NAME = \"500.pth\"  # Model filename\n",
    "MODEL_PATH = \"/home/benio/Documents/GNNBenchmark/ResultsRecognition/Recognition_EVGNN_on_ncaltech1/TrainedModels\"  # Path to trained models\n",
    "\n",
    "# Dataset Configuration\n",
    "DATASET = \"ncaltech\"  # \"ncars\" or \"ncaltech\"\n",
    "DATASET_PATHS = {\n",
    "    \"ncars\": r\"/home/benio/Documents/Datasets/NCars\",\n",
    "    \"ncaltech\": r\"/home/benio/Documents/Datasets/NCaltech\"\n",
    "}\n",
    "\n",
    "# Evaluation Configuration\n",
    "NUM_SAMPLES = 10  # Number of test samples to evaluate\n",
    "EVENTS_PER_SAMPLE = 5000  # Number of events to process per sample for async metrics\n",
    "N_EVENTS_SAMPLE = 10000  # Number of events to sample per recording\n",
    "\n",
    "# Output Configuration\n",
    "OUTPUT_DIR = \"../results/async_test_results2\"  # Directory to save results (same location as models)\n",
    "\n",
    "# Graph Construction Parameters\n",
    "RADIUS = 5.0  # Radius for graph construction\n",
    "MAX_NUM_NEIGHBORS = 32  # Max neighbors in graph\n",
    "MAX_DT = 66000  # Max time difference for edges\n",
    "BETA = 0.1e-4  # Time normalization beta\n",
    "USE_MICROSECONDS = False  # Model was trained with normalized timestamps!\n",
    "\n",
    "# Device Configuration\n",
    "DEVICE = \"cuda\""
   ],
   "id": "7671d3b9a9f39587",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-20T16:21:03.920361016Z",
     "start_time": "2026-01-20T16:21:00.710643045Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import gc\n",
    "import torch\n",
    "import numpy as np\n",
    "import json\n",
    "from copy import deepcopy\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.nn.pool import radius_graph\n",
    "from torch_geometric.transforms import Cartesian\n",
    "from tqdm import tqdm\n",
    "\n",
    "from src.Models.CleanEvGNN.GraphRes_Base import GraphRes as EvGNN\n",
    "from Models.CleanEvGNN.asyncronous import make_model_asynchronous, reset_async_module\n",
    "from Models.CleanEvGNN.asyncronous_aegnn import make_model_asynchronous as make_model_asynchronous_aegnn\n",
    "from Models.CleanEvGNN.asyncronous_aegnn import reset_async_module as reset_async_module_aegnn\n",
    "from Datasets.ncars import NCars\n",
    "from Datasets.ncaltech101 import NCaltech\n",
    "from Datasets.batching import BatchManager\n",
    "from Models.utils import normalize_time, sub_sampling\n",
    "\n",
    "# Optional: Power consumption tracking (only available on Linux with AIPowerMeter)\n",
    "try:\n",
    "    from Benchmarks.ModelTester import ModelTester\n",
    "    POWER_TRACKING_AVAILABLE = True\n",
    "    print(\"‚úì Power consumption tracking available\")\n",
    "except ImportError:\n",
    "    POWER_TRACKING_AVAILABLE = False\n",
    "    print(\"‚ö†Ô∏è  Power consumption tracking not available (AIPowerMeter not installed)\")\n",
    "\n"
   ],
   "id": "f767497e56c539d0",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/benio/miniconda3/envs/gnn-benchmarking/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Power consumption tracking available\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Load Datset and Model",
   "id": "f19c993596594532"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-20T16:21:05.316626377Z",
     "start_time": "2026-01-20T16:21:03.950714057Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "\n",
    "dataset_path = DATASET_PATHS[DATASET]\n",
    "\n",
    "if DATASET == 'ncars':\n",
    "    dataset_obj = NCars(root=dataset_path)\n",
    "    num_classes = len(NCars.get_info().classes)\n",
    "    image_size = NCars.get_info().image_size\n",
    "elif DATASET == 'ncaltech':\n",
    "    dataset_obj = NCaltech(root=dataset_path)\n",
    "    num_classes = len(NCaltech.get_info().classes)\n",
    "    image_size = NCaltech.get_info().image_size\n",
    "else:\n",
    "    raise ValueError(f\"Unknown dataset: {DATASET}\")\n",
    "\n",
    "dataset_obj.process(modes=[\"test\"])\n",
    "num_test_samples = dataset_obj.get_mode_length(\"test\")"
   ],
   "id": "9ad8bcdaca05f4bd",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x\n",
      "\n",
      "üìÇ Processing folder: mayfly\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "mayfly: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:00<00:00, 21732.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìÇ Processing folder: starfish\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "starfish: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:00<00:00, 55333.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìÇ Processing folder: pizza\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pizza: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6/6 [00:00<00:00, 36684.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìÇ Processing folder: tick\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tick: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6/6 [00:00<00:00, 37504.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìÇ Processing folder: strawberry\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "strawberry: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:00<00:00, 18766.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìÇ Processing folder: hawksbill\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "hawksbill: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:00<00:00, 61141.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìÇ Processing folder: grand_piano\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "grand_piano: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 11/11 [00:00<00:00, 68049.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìÇ Processing folder: stapler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "stapler: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:00<00:00, 22310.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìÇ Processing folder: scissors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "scissors: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:00<00:00, 27025.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìÇ Processing folder: cannon\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "cannon: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:00<00:00, 81284.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìÇ Processing folder: ibis\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ibis: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:00<00:00, 31714.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìÇ Processing folder: garfield\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "garfield: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:00<00:00, 23045.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìÇ Processing folder: inline_skate\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "inline_skate: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:00<00:00, 35544.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìÇ Processing folder: cup\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "cup: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:00<00:00, 47355.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìÇ Processing folder: saxophone\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "saxophone: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:00<00:00, 25653.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìÇ Processing folder: metronome\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "metronome: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:00<00:00, 29382.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìÇ Processing folder: camera\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "camera: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:00<00:00, 27271.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìÇ Processing folder: schooner\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "schooner: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:00<00:00, 40777.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìÇ Processing folder: elephant\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "elephant: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:00<00:00, 40440.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìÇ Processing folder: windsor_chair\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "windsor_chair: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:00<00:00, 30711.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìÇ Processing folder: watch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "watch: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 25/25 [00:00<00:00, 73947.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìÇ Processing folder: dollar_bill\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dollar_bill: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6/6 [00:00<00:00, 41120.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìÇ Processing folder: brontosaurus\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "brontosaurus: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:00<00:00, 24643.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìÇ Processing folder: nautilus\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "nautilus: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6/6 [00:00<00:00, 35899.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìÇ Processing folder: lotus\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "lotus: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:00<00:00, 42799.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìÇ Processing folder: scorpion\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "scorpion: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 9/9 [00:00<00:00, 59353.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìÇ Processing folder: ketch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ketch: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 12/12 [00:00<00:00, 65112.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìÇ Processing folder: cougar_body\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "cougar_body: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6/6 [00:00<00:00, 47127.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìÇ Processing folder: Faces_easy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Faces_easy: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 44/44 [00:00<00:00, 145428.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìÇ Processing folder: lamp\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "lamp: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:00<00:00, 54674.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìÇ Processing folder: pigeon\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pigeon: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:00<00:00, 39272.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìÇ Processing folder: flamingo_head\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "flamingo_head: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:00<00:00, 38409.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìÇ Processing folder: gerenuk\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "gerenuk: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:00<00:00, 79137.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìÇ Processing folder: okapi\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "okapi: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:00<00:00, 37786.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìÇ Processing folder: water_lilly\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "water_lilly: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:00<00:00, 37052.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìÇ Processing folder: accordion\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "accordion: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6/6 [00:00<00:00, 41527.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìÇ Processing folder: crocodile\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "crocodile: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:00<00:00, 39494.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìÇ Processing folder: platypus\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "platypus: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:00<00:00, 21704.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìÇ Processing folder: minaret\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "minaret: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 9/9 [00:00<00:00, 56850.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìÇ Processing folder: brain\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "brain: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 11/11 [00:00<00:00, 63115.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìÇ Processing folder: crab\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "crab: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:00<00:00, 44798.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìÇ Processing folder: trilobite\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "trilobite: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:00<00:00, 55115.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìÇ Processing folder: sunflower\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sunflower: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 9/9 [00:00<00:00, 48272.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìÇ Processing folder: yin_yang\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "yin_yang: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6/6 [00:00<00:00, 59353.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìÇ Processing folder: barrel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "barrel: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6/6 [00:00<00:00, 40394.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìÇ Processing folder: rooster\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "rooster: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6/6 [00:00<00:00, 40265.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìÇ Processing folder: joshua_tree\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "joshua_tree: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:00<00:00, 102657.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìÇ Processing folder: flamingo\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "flamingo: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:00<00:00, 66708.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìÇ Processing folder: panda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "panda: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:00<00:00, 35069.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìÇ Processing folder: cougar_face\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "cougar_face: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:00<00:00, 52103.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìÇ Processing folder: wrench\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wrench: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:00<00:00, 37315.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìÇ Processing folder: car_side\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "car_side: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:00<00:00, 73287.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìÇ Processing folder: chandelier\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "chandelier: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 12/12 [00:00<00:00, 150243.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìÇ Processing folder: crayfish\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "crayfish: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:00<00:00, 48933.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìÇ Processing folder: electric_guitar\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "electric_guitar: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:00<00:00, 56679.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìÇ Processing folder: bass\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bass: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6/6 [00:00<00:00, 12464.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìÇ Processing folder: dragonfly\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dragonfly: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:00<00:00, 53092.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìÇ Processing folder: mandolin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "mandolin: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:00<00:00, 37052.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìÇ Processing folder: bonsai\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bonsai: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 14/14 [00:00<00:00, 83528.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìÇ Processing folder: binocular\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "binocular: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:00<00:00, 35394.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìÇ Processing folder: emu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "emu: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6/6 [00:00<00:00, 50131.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìÇ Processing folder: chair\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "chair: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:00<00:00, 31536.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìÇ Processing folder: laptop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "laptop: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 9/9 [00:00<00:00, 66811.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìÇ Processing folder: stegosaurus\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "stegosaurus: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:00<00:00, 48131.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìÇ Processing folder: ceiling_fan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ceiling_fan: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6/6 [00:00<00:00, 55553.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìÇ Processing folder: rhino\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "rhino: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:00<00:00, 49678.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìÇ Processing folder: dalmatian\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dalmatian: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:00<00:00, 34592.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìÇ Processing folder: wild_cat\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wild_cat: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:00<00:00, 30504.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìÇ Processing folder: anchor\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "anchor: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:00<00:00, 37315.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìÇ Processing folder: buddha\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "buddha: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 9/9 [00:00<00:00, 48708.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìÇ Processing folder: revolver\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "revolver: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 9/9 [00:00<00:00, 60983.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìÇ Processing folder: ferry\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ferry: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:00<00:00, 51463.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìÇ Processing folder: wheelchair\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wheelchair: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:00<00:00, 47355.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìÇ Processing folder: llama\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 9/9 [00:00<00:00, 53017.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìÇ Processing folder: helicopter\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "helicopter: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:00<00:00, 65741.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìÇ Processing folder: hedgehog\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "hedgehog: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6/6 [00:00<00:00, 37172.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìÇ Processing folder: euphonium\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "euphonium: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:00<00:00, 46236.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìÇ Processing folder: stop_sign\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "stop_sign: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:00<00:00, 37884.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìÇ Processing folder: snoopy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "snoopy: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:00<00:00, 65281.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìÇ Processing folder: butterfly\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "butterfly: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:00<00:00, 56450.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìÇ Processing folder: headphone\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "headphone: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:00<00:00, 43329.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìÇ Processing folder: kangaroo\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "kangaroo: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:00<00:00, 63167.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìÇ Processing folder: airplanes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "airplanes: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 80/80 [00:00<00:00, 175493.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìÇ Processing folder: ewer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ewer: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 9/9 [00:00<00:00, 66342.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìÇ Processing folder: dolphin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dolphin: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:00<00:00, 50360.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìÇ Processing folder: pyramid\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pyramid: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:00<00:00, 47051.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìÇ Processing folder: menorah\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "menorah: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:00<00:00, 47662.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìÇ Processing folder: gramophone\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "gramophone: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6/6 [00:00<00:00, 38421.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìÇ Processing folder: ant\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ant: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:00<00:00, 44431.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìÇ Processing folder: crocodile_head\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "crocodile_head: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6/6 [00:00<00:00, 41187.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìÇ Processing folder: beaver\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "beaver: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6/6 [00:00<00:00, 46006.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìÇ Processing folder: soccer_ball\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "soccer_ball: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:00<00:00, 46163.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìÇ Processing folder: Leopards\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Leopards: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 20/20 [00:00<00:00, 99273.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìÇ Processing folder: cellphone\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "cellphone: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:00<00:00, 53674.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìÇ Processing folder: umbrella\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "umbrella: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:00<00:00, 55924.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìÇ Processing folder: octopus\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "octopus: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:00<00:00, 30727.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìÇ Processing folder: pagoda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pagoda: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6/6 [00:00<00:00, 40136.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìÇ Processing folder: lobster\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "lobster: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:00<00:00, 33341.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìÇ Processing folder: Motorbikes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Motorbikes: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 81/81 [00:00<00:00, 143896.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìÇ Processing folder: sea_horse\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sea_horse: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:00<00:00, 49678.73it/s]\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-20T16:21:05.618541469Z",
     "start_time": "2026-01-20T16:21:05.324355693Z"
    }
   },
   "cell_type": "code",
   "source": [
    "device = torch.device(DEVICE)\n",
    "img_shape = (image_size[1], image_size[0])\n",
    "\n",
    "model = EvGNN(\n",
    "    input_shape = torch.tensor([*img_shape, 3]),\n",
    "    dataset=DATASET,\n",
    "    num_outputs=num_classes,\n",
    "    conv_type=CONV_TYPE,\n",
    "    distill=False\n",
    ").to(device)\n",
    "\n",
    "model_path = os.path.join(MODEL_PATH, MODEL_NAME)\n",
    "if not os.path.exists(model_path):\n",
    "    raise FileNotFoundError(f\"Model not found: {model_path}\")\n",
    "\n",
    "model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "model.eval()"
   ],
   "id": "70dde16c49a4dec0",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GraphRes(\n",
       "  (fuse1): MyConvBNReLU(1, 16)\n",
       "  (fuse2): MyConvBNReLU(16, 32)\n",
       "  (fuse3): MyConvBNReLU(32, 32)\n",
       "  (fuse4): MyConvBNReLU(32, 32)\n",
       "  (pool): MaxPoolingX(voxel_size=tensor([16., 16.], device='cuda:0'), size=180)\n",
       "  (fc): qLinear(\n",
       "    (lin): Linear(in_features=5760, out_features=101, bias=False)\n",
       "    (obs_in): MinMaxObserver(min_val=0.0, max_val=6.4146342277526855)\n",
       "    (obs_out): MinMaxObserver(min_val=-63.36524200439453, max_val=17.986724853515625)\n",
       "    (obs_w): MinMaxObserver(min_val=-0.7886757254600525, max_val=0.149931401014328)\n",
       "  )\n",
       "  (drop): Dropout(p=0.0, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-20T16:21:05.627076144Z",
     "start_time": "2026-01-20T16:21:05.620381833Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def transform_sample(sample, device):\n",
    "    \"\"\"Apply preprocessing to match original AEGNN dataset pre_transform\"\"\"\n",
    "    sample = sample.to(device)\n",
    "\n",
    "    # Normalize polarity\n",
    "    sample.x = torch.where(sample.x == -1., 0., sample.x)\n",
    "\n",
    "    # Subsample events\n",
    "    sample = sub_sampling(sample, n_samples=N_EVENTS_SAMPLE, sub_sample=True)\n",
    "\n",
    "    if USE_MICROSECONDS:\n",
    "        sample.pos[:, 2] = torch.round(sample.pos[:, 2] * 1e6)\n",
    "    else:\n",
    "        sample.pos[:, 2] = normalize_time(sample.pos[:, 2], beta=BETA)\n",
    "\n",
    "    # Build graph with standard radius_graph\n",
    "    sample.edge_index = radius_graph(sample.pos, r=RADIUS, max_num_neighbors=MAX_NUM_NEIGHBORS)\n",
    "\n",
    "    # Add edge attributes\n",
    "    edge_attr_fn = Cartesian(cat=False, max_value=RADIUS)\n",
    "    sample.edge_attr = edge_attr_fn(sample).edge_attr\n",
    "\n",
    "    return sample"
   ],
   "id": "f71df5be6817042",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Setup Async Model and test",
   "id": "84673fc12f520c04"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-20T16:21:05.639661459Z",
     "start_time": "2026-01-20T16:21:05.627919725Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "test_loader = BatchManager(dataset=dataset_obj, batch_size=1, mode=\"test\")\n",
    "num_samples = min(NUM_SAMPLES, num_test_samples)\n",
    "\n",
    "edge_attributes = Cartesian(norm=True, cat=False)\n",
    "\n",
    "model_for_async = deepcopy(model)\n",
    "\n",
    "if CONV_TYPE == 'ori_aegnn':\n",
    "    async_model = make_model_asynchronous_aegnn(model_for_async, r=RADIUS, edge_attributes=edge_attributes,\n",
    "                                                log_flops=False, log_runtime=False)\n",
    "    reset_async_fn = reset_async_module_aegnn\n",
    "else:\n",
    "    async_model = make_model_asynchronous(model_for_async, r=RADIUS, max_num_neighbors=MAX_NUM_NEIGHBORS,\n",
    "                                          max_dt=MAX_DT, edge_attributes=edge_attributes,\n",
    "                                          log_flops=False, log_runtime=False)\n",
    "    reset_async_fn = reset_async_module\n",
    "\n"
   ],
   "id": "2d551473f725d14c",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Run Full Async Evaluation",
   "id": "7a2aa1ee8c2655bf"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-20T16:23:36.063480488Z",
     "start_time": "2026-01-20T16:21:05.640282398Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "# Initialize power consumption tracking\n",
    "model_tester = None\n",
    "if POWER_TRACKING_AVAILABLE and sys.platform == \"linux\":\n",
    "    power_output_dir = os.path.join(OUTPUT_DIR, \"power_consumption\")\n",
    "    os.makedirs(power_output_dir, exist_ok=True)\n",
    "    model_tester = ModelTester(\n",
    "        results_path=power_output_dir,\n",
    "        model=async_model\n",
    "    )\n",
    "    print(\"‚úì Power consumption tracking initialized\")\n",
    "elif POWER_TRACKING_AVAILABLE:\n",
    "    print(\"‚ö†Ô∏è  Power tracking only works on Linux, skipping measurement\")\n",
    "\n",
    "per_event_latencies = []\n",
    "all_predictions = []\n",
    "all_targets = []\n",
    "predictions_per_event = []\n",
    "successful_samples = 0\n",
    "failed_samples = 0\n",
    "\n",
    "gc.collect()\n",
    "if device.type == 'cuda':\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "events_to_process = min(EVENTS_PER_SAMPLE, N_EVENTS_SAMPLE)\n",
    "\n",
    "##\n",
    "##  Training loop with power measurement\n",
    "##\n",
    "\n",
    "\n",
    "# Use context manager for power measurement (like in training script)\n",
    "if model_tester is not None:\n",
    "    print(\"testing\")\n",
    "    # Wrap evaluation loop with power measurement\n",
    "    with model_tester:\n",
    "        for i in tqdm(range(num_samples), desc=\"Async inference\"):\n",
    "            try:\n",
    "                sample = next(test_loader)\n",
    "                sample = transform_sample(sample, device)\n",
    "                target_class = sample.y.item()\n",
    "                all_targets.append(target_class)\n",
    "\n",
    "                reset_async_fn(async_model)\n",
    "\n",
    "                num_events = min(sample.num_nodes, events_to_process)\n",
    "                sample_predictions = []\n",
    "\n",
    "                with torch.no_grad():\n",
    "                    for event_idx in range(num_events):\n",
    "                        event_new = Data(\n",
    "                            x=sample.x[event_idx:event_idx+1],\n",
    "                            pos=sample.pos[event_idx:event_idx+1, :3],\n",
    "                            batch=torch.zeros(1, dtype=torch.long),\n",
    "                            edge_index=torch.empty((2, 0), dtype=torch.long),\n",
    "                            edge_attr=torch.empty((0, 3), dtype=torch.float)\n",
    "                        ).to(device)\n",
    "\n",
    "                        event_start = time.perf_counter()\n",
    "                        output = async_model(event_new)\n",
    "                        latency = (time.perf_counter() - event_start) * 1000\n",
    "                        per_event_latencies.append(latency)\n",
    "\n",
    "                        pred = torch.argmax(output, dim=-1).item()\n",
    "                        sample_predictions.append(pred)\n",
    "\n",
    "                        if event_idx == num_events - 1:\n",
    "                            all_predictions.append(pred)\n",
    "\n",
    "                predictions_per_event.append(sample_predictions)\n",
    "                successful_samples += 1\n",
    "\n",
    "            except (IndexError, RuntimeError) as e:\n",
    "                print(e)\n",
    "                failed_samples += 1\n",
    "                if len(all_targets) > len(all_predictions):\n",
    "                    all_predictions.append(0)\n",
    "                predictions_per_event.append([0])\n",
    "                continue\n",
    "\n",
    "\n",
    "##\n",
    "## Training loop without power measurement\n",
    "##\n",
    "\n",
    "else:\n",
    "    # No power measurement\n",
    "    pass\n"
   ],
   "id": "59535c9325b95e48",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Power consumption tracking initialized\n",
      "testing\n",
      "power meter not avaible: /home/ntirel/libs/wattmeter_rapid_omegawatt/wattmetre-read  does not exist\n",
      "GPU power will be measured with nvidia\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Async inference: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [02:29<00:00, 15.00s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with measuring\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Calculate Metrics\n",
   "id": "78b9ab8ce7ef9b8e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-20T16:23:36.132497218Z",
     "start_time": "2026-01-20T16:23:36.077674663Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "# Compute metrics\n",
    "predictions = np.array(all_predictions)\n",
    "targets = np.array(all_targets)\n",
    "accuracy_final = (predictions == targets).mean()\n",
    "\n",
    "\n",
    "# Compute latency statistics\n",
    "latency_mean = float(np.mean(per_event_latencies))\n",
    "latency_std = float(np.std(per_event_latencies))\n",
    "\n",
    "# Compute accuracy evolution over events\n",
    "max_events = max(len(preds) for preds in predictions_per_event)\n",
    "accuracy_evolution = []\n",
    "for event_idx in range(max_events):\n",
    "    correct = sum(1 for sample_idx, sample_preds in enumerate(predictions_per_event)\n",
    "                 if event_idx < len(sample_preds) and sample_preds[event_idx] == all_targets[sample_idx])\n",
    "    total = sum(1 for sample_preds in predictions_per_event if event_idx < len(sample_preds))\n",
    "    accuracy_evolution.append(correct / total if total > 0 else 0.0)\n",
    "\n",
    "# Count correct/incorrect predictions\n",
    "num_correct = int((predictions == targets).sum())\n",
    "num_incorrect = successful_samples - num_correct\n",
    "\n",
    "# Print results\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"ASYNCHRONOUS EVALUATION RESULTS\")\n",
    "print(\"=\"*70)\n",
    "print(f\"Accuracy: {accuracy_final:.4f} ({num_correct}/{successful_samples} correct)\")\n",
    "print(f\"Latency:  {latency_mean:.4f} ¬± {latency_std:.4f} ms\")\n",
    "print(f\"Samples:  {successful_samples}/{num_samples} successful\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Power consumption summary\n",
    "power_summary = None\n",
    "if model_tester is not None:\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"POWER CONSUMPTION\")\n",
    "    print(\"=\"*70)\n",
    "    try:\n",
    "        if model_tester._power_consumption_results_exist():\n",
    "            model_tester.print_power_consumption()\n",
    "            power_summary = model_tester.summarize_power_consumption()\n",
    "            print(\"‚úì Power consumption data collected\")\n",
    "        else:\n",
    "            print(\"‚ö†Ô∏è  No power consumption data found\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è  Could not retrieve power consumption: {e}\")\n",
    "    print(\"=\"*70)\n",
    "\n",
    "# Save accuracy evolution to CSV\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "model_name = os.path.splitext(MODEL_NAME)[0]\n",
    "base_name = f\"{model_name}_{DATASET}\"\n",
    "\n",
    "csv_path = os.path.join(OUTPUT_DIR, f\"{base_name}_accuracy_evolution.csv\")\n",
    "with open(csv_path, 'w') as f:\n",
    "    f.write(\"event_index,accuracy\\n\")\n",
    "    for idx, acc in enumerate(accuracy_evolution):\n",
    "        f.write(f\"{idx},{acc:.6f}\\n\")\n",
    "\n",
    "# Save metrics to JSON\n",
    "json_path = os.path.join(OUTPUT_DIR, f\"{base_name}_metrics.json\")\n",
    "all_metrics = {\n",
    "    'model': MODEL_NAME,\n",
    "    'dataset': DATASET,\n",
    "    'accuracy': float(accuracy_final),\n",
    "    'latency_mean_ms': latency_mean,\n",
    "    'latency_std_ms': latency_std,\n",
    "    'num_correct': num_correct,\n",
    "    'num_incorrect': num_incorrect,\n",
    "    'successful_samples': successful_samples,\n",
    "    'failed_samples': failed_samples\n",
    "}\n",
    "\n",
    "# Add power consumption metrics if available\n",
    "if power_summary is not None:\n",
    "    all_metrics['power_consumption'] = power_summary\n",
    "\n",
    "with open(json_path, 'w') as f:\n",
    "    json.dump(all_metrics, f, indent=2)\n"
   ],
   "id": "8d9949a150e3f84e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "ASYNCHRONOUS EVALUATION RESULTS\n",
      "======================================================================\n",
      "Accuracy: 0.3000 (3/10 correct)\n",
      "Latency:  2.9112 ¬± 1.0994 ms\n",
      "Samples:  10/10 successful\n",
      "======================================================================\n",
      "\n",
      "======================================================================\n",
      "POWER CONSUMPTION\n",
      "======================================================================\n",
      "============================================ EXPERIMENT SUMMARY ============================================\n",
      "\n",
      "Experiment duration:  148.09908413887024 seconds.  Start: 2026-01-20 17:21:07.293959  end 2026-01-20 17:23:35.393043\n",
      "ENERGY CONSUMPTION: \n",
      "on the cpu\n",
      "\n",
      "CPU time usage of your experiment: 148.40956218004231 seconds\n",
      "RAM consumption not available. Your usage was  1.3GiB among which 916.3MiB is unique to your experiment (ie. USS memory)\n",
      "Total CPU consumption: 28.857043261945805 joules, your experiment consumption:  26.201706198542208 joules\n",
      "total intel power:  3145.549999691258 joules\n",
      "total psys power:  -148.09908413887024 joules\n",
      "\n",
      "\n",
      "GPU\n",
      "nvidia total consumption: 3524.102981171607 joules, your consumption:  3175.6112851513712 joules\n",
      "Max memory used:\n",
      "    gpu: 0 : 212.0MiB\n",
      "Average GPU usage:\n",
      "    gpu: 0: 16.568 %\n",
      "Attributable usage per GPU\n",
      "    gpu: 0: 3175.611 joules\n",
      "‚úì Power consumption data collected\n",
      "======================================================================\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-20T16:23:36.139659881Z",
     "start_time": "2026-01-20T16:23:36.134488540Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# # Analyze predictions - check if model predicted varied classes\n",
    "# print(\"\\n\" + \"=\"*70)\n",
    "# print(\"PREDICTION ANALYSIS\")\n",
    "# print(\"=\"*70)\n",
    "#\n",
    "# # Count unique predictions\n",
    "# unique_preds, pred_counts = np.unique(predictions, return_counts=True)\n",
    "# print(f\"\\nTotal predictions: {len(predictions)}\")\n",
    "# print(f\"Unique classes predicted: {len(unique_preds)}/{num_classes}\")\n",
    "# print(f\"\\nPrediction distribution:\")\n",
    "# for cls, count in zip(unique_preds, pred_counts):\n",
    "#     percentage = (count / len(predictions)) * 100\n",
    "#     print(f\"  Class {int(cls)}: {count:3d} times ({percentage:5.1f}%)\")\n",
    "#\n",
    "# # Check if model is stuck predicting one class\n",
    "# if len(unique_preds) == 1:\n",
    "#     print(f\"\\n‚ùå WARNING: Model predicted ONLY class {int(unique_preds[0])}!\")\n",
    "#     print(f\"   The model is stuck and not working properly.\")\n",
    "# elif len(unique_preds) < num_classes / 2:\n",
    "#     print(f\"\\n‚ö†Ô∏è  Model only uses {len(unique_preds)} out of {num_classes} classes\")\n",
    "#     print(f\"   This may indicate a problem with the model or data.\")\n",
    "# else:\n",
    "#     print(f\"\\n‚úì Model uses {len(unique_preds)} different classes (good diversity)\")\n",
    "#\n",
    "# # Show ground truth distribution for comparison\n",
    "# print(f\"\\nGround truth distribution:\")\n",
    "# unique_targets, target_counts = np.unique(targets, return_counts=True)\n",
    "# for cls, count in zip(unique_targets, target_counts):\n",
    "#     percentage = (count / len(targets)) * 100\n",
    "#     print(f\"  Class {int(cls)}: {count:3d} times ({percentage:5.1f}%)\")\n",
    "#\n",
    "# # Per-class accuracy\n",
    "# print(f\"\\nPer-class accuracy:\")\n",
    "# for cls in range(num_classes):\n",
    "#     cls_mask = targets == cls\n",
    "#     if cls_mask.sum() > 0:\n",
    "#         cls_acc = (predictions[cls_mask] == targets[cls_mask]).mean()\n",
    "#         cls_count = cls_mask.sum()\n",
    "#         correct = int(cls_acc * cls_count)\n",
    "#         print(f\"  Class {cls}: {cls_acc:.4f} ({correct}/{cls_count} correct)\")\n",
    "#\n",
    "# print(\"=\"*70)\n"
   ],
   "id": "cc5c7842a08c3307",
   "outputs": [],
   "execution_count": 9
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
